{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Importing the 4 dataframes containing all raw data\n",
    "from extract_into_dfs import academy_csvs_df, talent_csvs_df, talent_jsons_df, talent_txts_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Academy CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academy_csvs_df['name'].duplicated().sum()\n",
    "\n",
    "# This equals 0, i.e. there are no duplicated names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Similarity to other names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>MONA ORVISS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>OMERO SHILL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VERNE FRANCESCUZZI</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>HORTEN KOOMAR</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>LILLY ANDREASEN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOLANDA FOSSE</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GUSTAF LUDE</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIMON MURREY</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>THOM DERWIN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>GODFRY SEPHTON</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  Similarity to other names\n",
       "111         MONA ORVISS                          4\n",
       "87          OMERO SHILL                          4\n",
       "21   VERNE FRANCESCUZZI                          4\n",
       "391       HORTEN KOOMAR                          4\n",
       "367     LILLY ANDREASEN                          4\n",
       "..                  ...                        ...\n",
       "3         YOLANDA FOSSE                        100\n",
       "2           GUSTAF LUDE                        100\n",
       "1          SIMON MURREY                        100\n",
       "395         THOM DERWIN                        100\n",
       "396      GODFRY SEPHTON                        100\n",
       "\n",
       "[397 rows x 2 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for near duplicates\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "academy_csvs_df['Similarity to other names'] = academy_csvs_df['name'].apply(lambda x: fuzz.token_set_ratio(x, academy_csvs_df['name']))\n",
    "\n",
    "academy_csvs_df[['name', 'Similarity to other names']].sort_values('Similarity to other names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Similarity to other names', ylabel='Count'>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+J0lEQVR4nO3de1xVdb7/8ffe3BUBReWSoHi/m6kpallGqVONJlNTPyvtXmOW2jTFKbNxarBmvJSRTh3DOmWWM2pZjU6iWSbeMG+pqIlBKlAaoCgX9/7+/vC4T+QNEVh74ev5eKyHrO9a+7s++7t94Nu1vmsvhzHGCAAAwIacVhcAAABQVQQZAABgWwQZAABgWwQZAABgWwQZAABgWwQZAABgWwQZAABgW75WF1DT3G63Dhw4oAYNGsjhcFhdDgAAqARjjI4cOaLo6Gg5nWc/71Lng8yBAwcUExNjdRkAAKAKcnJy1KxZs7Nur/NBpkGDBpJODkRISIjF1QAAgMooKipSTEyM59/xs6nzQebU5aSQkBCCDAAANnO+aSFM9gUAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALZFkAEAALbla3UBqByXy6Xs7GzPemxsrHx8fCysCAAA6xFkbCI7O1tTFqxWWJNIFfyYqyeGS3FxcVaXBQCApQgyNhLWJFLhUTFWlwEAgNdgjgwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtS4OMy+XShAkTFBcXp6CgILVq1Up/+ctfZIzx7GOM0XPPPaeoqCgFBQUpISFBu3fvtrBqAADgLSwNMi+99JJmzpyp1157TTt27NBLL72kl19+WTNmzPDs8/LLL+vVV1/VrFmztHbtWtWvX1+DBg1SSUmJhZUDAABv4GvlwVevXq2hQ4fqxhtvlCS1aNFC77//vtatWyfp5NmY6dOn69lnn9XQoUMlSe+8844iIiK0aNEi3X777af1WVpaqtLSUs96UVFRLbyT6uVyuZSdne1Zj42NtbAaAAC8l6VnZPr27au0tDTt2rVLkrR582atWrVKQ4YMkSRlZWUpNzdXCQkJnteEhoaqd+/eSk9PP2OfycnJCg0N9SwxMTE1/0aqWXZ2tqYsWK3ZX+3VlAWrK4QaAADwfyw9I/P000+rqKhI7du3l4+Pj1wul1588UWNGDFCkpSbmytJioiIqPC6iIgIz7ZfS0pK0vjx4z3rRUVFtgwzYU0iFR5lv7oBAKhNlgaZDz/8UO+9957mzp2rTp06adOmTRo7dqyio6M1cuTIKvUZEBCggICAaq4UAAB4I0uDzJNPPqmnn37aM9elS5cu+v7775WcnKyRI0cqMjJSkpSXl6eoqCjP6/Ly8nT55ZdbUTIAAPAils6ROXbsmJzOiiX4+PjI7XZLkuLi4hQZGam0tDTP9qKiIq1du1bx8fG1WisAAPA+lp6Rufnmm/Xiiy8qNjZWnTp10jfffKOpU6fq3nvvlSQ5HA6NHTtWL7zwgtq0aaO4uDhNmDBB0dHRGjZsmJWlAwAAL2BpkJkxY4YmTJigP/zhD8rPz1d0dLQeeughPffcc559/vSnP6m4uFgPPvigCgoK1L9/fy1ZskSBgYEWVg4AALyBpUGmQYMGmj59uqZPn37WfRwOhyZNmqRJkybVXmEAAMAWeNYSAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLUuDTIsWLeRwOE5bRo8eLUkqKSnR6NGjFR4eruDgYCUmJiovL8/KkgEAgBexNMisX79eBw8e9Cyff/65JOnWW2+VJI0bN06LFy/W/PnztXLlSh04cEDDhw+3smQAAOBFfK08eJMmTSqsT548Wa1atdKAAQNUWFio2bNna+7cuRo4cKAkKTU1VR06dNCaNWvUp08fK0oGAABexGvmyJSVlendd9/VvffeK4fDoYyMDJWXlyshIcGzT/v27RUbG6v09PSz9lNaWqqioqIKCwAAqJu8JsgsWrRIBQUFGjVqlCQpNzdX/v7+CgsLq7BfRESEcnNzz9pPcnKyQkNDPUtMTEwNVg0AAKzkNUFm9uzZGjJkiKKjoy+qn6SkJBUWFnqWnJycaqoQAAB4G0vnyJzy/fffa9myZVqwYIGnLTIyUmVlZSooKKhwViYvL0+RkZFn7SsgIEABAQE1WS4AAPASXnFGJjU1VU2bNtWNN97oaevRo4f8/PyUlpbmacvMzFR2drbi4+OtKBMAAHgZy8/IuN1upaamauTIkfL1/b9yQkNDdd9992n8+PFq1KiRQkJCNGbMGMXHx3PHEgAAkOQFQWbZsmXKzs7Wvffee9q2adOmyel0KjExUaWlpRo0aJBef/11C6oEAADeyPIgc8MNN8gYc8ZtgYGBSklJUUpKSi1XBQAA7MAr5sgAAABUBUEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYlq/VBVzqXC6XsrOzPeuxsbEWVgMAgL0QZCyWnZ2tKQtWK6xJpAp+zNUTw62uCAAA+yDIeIGwJpEKj4qxugwAAGyHOTIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2CDIAAMC2LA8y+/fv15133qnw8HAFBQWpS5cu2rBhg2e7MUbPPfecoqKiFBQUpISEBO3evdvCigEAgLewNMj8/PPP6tevn/z8/PTvf/9b27dv15QpU9SwYUPPPi+//LJeffVVzZo1S2vXrlX9+vU1aNAglZSUWFg5AADwBpY+/fqll15STEyMUlNTPW1xcXGen40xmj59up599lkNHTpUkvTOO+8oIiJCixYt0u23335an6WlpSotLfWsFxUV1eA7AAAAVrL0jMzHH3+snj176tZbb1XTpk3VvXt3vfnmm57tWVlZys3NVUJCgqctNDRUvXv3Vnp6+hn7TE5OVmhoqGeJiYmp8fcBAACsYWmQ2bt3r2bOnKk2bdpo6dKleuSRR/TYY4/p7bffliTl5uZKkiIiIiq8LiIiwrPt15KSklRYWOhZcnJyavZNAAAAy1h6acntdqtnz57661//Kknq3r27tm3bplmzZmnkyJFV6jMgIEABAQHVWSYAAPBSlp6RiYqKUseOHSu0dejQQdnZ2ZKkyMhISVJeXl6FffLy8jzbAADApcvSINOvXz9lZmZWaNu1a5eaN28u6eTE38jISKWlpXm2FxUVae3atYqPj6/VWgEAgPex9NLSuHHj1LdvX/31r3/VbbfdpnXr1umNN97QG2+8IUlyOBwaO3asXnjhBbVp00ZxcXGaMGGCoqOjNWzYMCtLBwAAXsDSINOrVy8tXLhQSUlJmjRpkuLi4jR9+nSNGDHCs8+f/vQnFRcX68EHH1RBQYH69++vJUuWKDAw0MLKAQCAN7A0yEjSTTfdpJtuuums2x0OhyZNmqRJkybVYlUAAMAOLH9EAQAAQFURZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG0RZAAAgG1ZGmSef/55ORyOCkv79u0920tKSjR69GiFh4crODhYiYmJysvLs7BiAADgTSw/I9OpUycdPHjQs6xatcqzbdy4cVq8eLHmz5+vlStX6sCBAxo+fLiF1QIAAG/ia3kBvr6KjIw8rb2wsFCzZ8/W3LlzNXDgQElSamqqOnTooDVr1qhPnz61XSoAAPAylp+R2b17t6Kjo9WyZUuNGDFC2dnZkqSMjAyVl5crISHBs2/79u0VGxur9PT0s/ZXWlqqoqKiCgsAAKibLA0yvXv31pw5c7RkyRLNnDlTWVlZuuqqq3TkyBHl5ubK399fYWFhFV4TERGh3Nzcs/aZnJys0NBQzxITE1PD7wIAAFjF0ktLQ4YM8fzctWtX9e7dW82bN9eHH36ooKCgKvWZlJSk8ePHe9aLiooIMwAA1FGWX1r6pbCwMLVt21Z79uxRZGSkysrKVFBQUGGfvLy8M86pOSUgIEAhISEVFgAAUDd5VZA5evSovvvuO0VFRalHjx7y8/NTWlqaZ3tmZqays7MVHx9vYZUAAMBbVCnItGzZUocOHTqtvaCgQC1btqx0P3/84x+1cuVK7du3T6tXr9Ytt9wiHx8f3XHHHQoNDdV9992n8ePHa8WKFcrIyNA999yj+Ph47lgCAACSqjhHZt++fXK5XKe1l5aWav/+/ZXu54cfftAdd9yhQ4cOqUmTJurfv7/WrFmjJk2aSJKmTZsmp9OpxMRElZaWatCgQXr99derUjIAAKiDLijIfPzxx56fly5dqtDQUM+6y+VSWlqaWrRoUen+5s2bd87tgYGBSklJUUpKyoWUCQAALhEXFGSGDRsmSXI4HBo5cmSFbX5+fmrRooWmTJlSbcUBAACcywUFGbfbLUmKi4vT+vXr1bhx4xopCgAAoDKqNEcmKyuruusAAAC4YFX+Qry0tDSlpaUpPz/fc6bmlLfeeuuiCwMAADifKgWZP//5z5o0aZJ69uypqKgoORyO6q4LAADgvKoUZGbNmqU5c+borrvuqu56AAAAKq1KX4hXVlamvn37VnctAAAAF6RKQeb+++/X3Llzq7sWAACAC1KlS0slJSV64403tGzZMnXt2lV+fn4Vtk+dOrVaigMAADiXKgWZLVu26PLLL5ckbdu2rcI2Jv4CAIDaUqUgs2LFiuquAwAA4IJVaY4MAACAN6jSGZlrr732nJeQli9fXuWCAAAAKqtKQebU/JhTysvLtWnTJm3btu20h0kCAADUlCoFmWnTpp2x/fnnn9fRo0cvqiAAAIDKqtY5MnfeeSfPWQIAALWmWoNMenq6AgMDq7NLAACAs6rSpaXhw4dXWDfG6ODBg9qwYYMmTJhQLYUBAACcT5WCTGhoaIV1p9Opdu3aadKkSbrhhhuqpTAAAIDzqVKQSU1Nre46AAAALliVgswpGRkZ2rFjhySpU6dO6t69e7UUBQAAUBlVCjL5+fm6/fbb9cUXXygsLEySVFBQoGuvvVbz5s1TkyZNqrNGAACAM6rSXUtjxozRkSNH9O233+rw4cM6fPiwtm3bpqKiIj322GPVXSMAAMAZVemMzJIlS7Rs2TJ16NDB09axY0elpKQw2RcAANSaKp2Rcbvd8vPzO63dz89Pbrf7oosCAACojCoFmYEDB+rxxx/XgQMHPG379+/XuHHjdN1111VbcQAAAOdSpSDz2muvqaioSC1atFCrVq3UqlUrxcXFqaioSDNmzKjuGgEAAM6oSnNkYmJitHHjRi1btkw7d+6UJHXo0EEJCQnVWhwAAMC5XNAZmeXLl6tjx44qKiqSw+HQ9ddfrzFjxmjMmDHq1auXOnXqpK+++qqmagUAAKjggoLM9OnT9cADDygkJOS0baGhoXrooYc0derUaiuurnG5XMrKyvIsLpfL6pIAALC1Cwoymzdv1uDBg8+6/YYbblBGRkaVCpk8ebIcDofGjh3raSspKdHo0aMVHh6u4OBgJSYmKi8vr0r9e4Ps7GxNWbBas7/aqykLVis7O9vqkgAAsLULCjJ5eXlnvO36FF9fX/34448XXMT69ev1j3/8Q127dq3QPm7cOC1evFjz58/XypUrdeDAgdOevG03YU0iFR4Vo7AmkVaXAgCA7V1QkLnsssu0bdu2s27fsmWLoqKiLqiAo0ePasSIEXrzzTfVsGFDT3thYaFmz56tqVOnauDAgerRo4dSU1O1evVqrVmz5oKOAQAA6qYLCjK/+c1vNGHCBJWUlJy27fjx45o4caJuuummCypg9OjRuvHGG0+74ykjI0Pl5eUV2tu3b6/Y2Filp6eftb/S0lIVFRVVWAAAQN10QbdfP/vss1qwYIHatm2rRx99VO3atZMk7dy5UykpKXK5XHrmmWcq3d+8efO0ceNGrV+//rRtubm58vf39zyU8pSIiAjl5uaetc/k5GT9+c9/rnQNAADAvi4oyERERGj16tV65JFHlJSUJGOMJMnhcGjQoEFKSUlRREREpfrKycnR448/rs8//1yBgYEXXvlZJCUlafz48Z71oqIixcTEVFv/AADAe1zwF+I1b95cn332mX7++Wft2bNHxhi1adOmwvyWysjIyFB+fr6uuOIKT5vL5dKXX36p1157TUuXLlVZWZkKCgoqnJXJy8tTZOTZJ8oGBAQoICDgQt8WAACwoSp9s68kNWzYUL169aryga+77jpt3bq1Qts999yj9u3b66mnnlJMTIz8/PyUlpamxMRESVJmZqays7MVHx9f5eMCAIC6o8pB5mI1aNBAnTt3rtBWv359hYeHe9rvu+8+jR8/Xo0aNVJISIjGjBmj+Ph49enTx4qSAQCAl7EsyFTGtGnT5HQ6lZiYqNLSUg0aNEivv/661WUBAAAv4VVB5osvvqiwHhgYqJSUFKWkpFhTEAAA8GoX9D0yAAAA3oQgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbMurvtkXleN2u5STk+NZj42NlY+Pj4UVAQBgDYKMDRUdytdb3x9Vs7hyFfyYqyeGS3FxcVaXBQBArSPI2FRI4wiFR8VYXQYAAJZijgwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtS4PMzJkz1bVrV4WEhCgkJETx8fH697//7dleUlKi0aNHKzw8XMHBwUpMTFReXp6FFQMAAG9iaZBp1qyZJk+erIyMDG3YsEEDBw7U0KFD9e2330qSxo0bp8WLF2v+/PlauXKlDhw4oOHDh1tZMgAA8CK+Vh785ptvrrD+4osvaubMmVqzZo2aNWum2bNna+7cuRo4cKAkKTU1VR06dNCaNWvUp0+fM/ZZWlqq0tJSz3pRUVHNvQEAAGApr5kj43K5NG/ePBUXFys+Pl4ZGRkqLy9XQkKCZ5/27dsrNjZW6enpZ+0nOTlZoaGhniUmJqY2ygcAABawPMhs3bpVwcHBCggI0MMPP6yFCxeqY8eOys3Nlb+/v8LCwirsHxERodzc3LP2l5SUpMLCQs+Sk5NTw+8AAABYxdJLS5LUrl07bdq0SYWFhfrnP/+pkSNHauXKlVXuLyAgQAEBAdVYIQAA8FaWBxl/f3+1bt1aktSjRw+tX79er7zyin7/+9+rrKxMBQUFFc7K5OXlKTIy0qJqAQCAN7H80tKvud1ulZaWqkePHvLz81NaWppnW2ZmprKzsxUfH29hhQAAwFtYekYmKSlJQ4YMUWxsrI4cOaK5c+fqiy++0NKlSxUaGqr77rtP48ePV6NGjRQSEqIxY8YoPj7+rHcsAQCAS4ulQSY/P1933323Dh48qNDQUHXt2lVLly7V9ddfL0maNm2anE6nEhMTVVpaqkGDBun111+3smQAAOBFLA0ys2fPPuf2wMBApaSkKCUlpZYqAgAAduJ1c2QAAAAqiyADAABsiyADAABsiyADAABsy/IvxEP1cLlcys7O9qzHxsbKx8fHwooAAKh5BJk6Ijs7W1MWrFZYk0gV/JirJ4ZLcXFxVpcFAECNIsjUIWFNIhUexdO+AQCXDubIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2/K1uoC6yuVyKTs727MeGxtrYTUAANRNBJkakp2drSkLViusSaQKfszVE8OtrggAgLqHIFODwppEKjwqxuoyAACos5gjAwAAbIsgAwAAbMvSIJOcnKxevXqpQYMGatq0qYYNG6bMzMwK+5SUlGj06NEKDw9XcHCwEhMTlZeXZ1HFAADAm1gaZFauXKnRo0drzZo1+vzzz1VeXq4bbrhBxcXFnn3GjRunxYsXa/78+Vq5cqUOHDig4cOZOQsAACye7LtkyZIK63PmzFHTpk2VkZGhq6++WoWFhZo9e7bmzp2rgQMHSpJSU1PVoUMHrVmzRn369LGibAAA4CW8ao5MYWGhJKlRo0aSpIyMDJWXlyshIcGzT/v27RUbG6v09PQz9lFaWqqioqIKCwAAqJu8Jsi43W6NHTtW/fr1U+fOnSVJubm58vf3V1hYWIV9IyIilJube8Z+kpOTFRoa6lliYrj9GQCAusprgszo0aO1bds2zZs376L6SUpKUmFhoWfJycmppgoBAIC38YovxHv00Uf1ySef6Msvv1SzZs087ZGRkSorK1NBQUGFszJ5eXmKjIw8Y18BAQEKCAio6ZIBAIAXsPSMjDFGjz76qBYuXKjly5crLi6uwvYePXrIz89PaWlpnrbMzExlZ2crPj6+tssFAABextIzMqNHj9bcuXP10UcfqUGDBp55L6GhoQoKClJoaKjuu+8+jR8/Xo0aNVJISIjGjBmj+Ph47lgCAADWBpmZM2dKkq655poK7ampqRo1apQkadq0aXI6nUpMTFRpaakGDRqk119/vZYrBQAA3sjSIGOMOe8+gYGBSklJUUpKSi1UBAAA7MRr7loCAAC4UAQZAABgW15x+zX+z/c/l+qrrCKlHyhXwM95OlFSrg77jqhns/pWlwYAgNchyHiJH34+puXflerd7d/9X2PByccrPLM0R/X8nGoZ6tCApm6LKgQAwPsQZCx2rMylNQfKtadgvyTJ1yn1aBas0uMlqh8Sqp8OF+hwmUM/Fp/Qtp+kH9Zlq6O/jxoHWlw4AABegCBjoYLjJ/TUZ9naU+CSJLVp6KO//7a1QgJ9NPurvQqPaqRDAcW6p3+cVmUd0eQVP6jgWLnSjzXQFT4uxZ2nfwAA6jqCjEWKy40e+3ifcgrKFOAj3dytmQJLflJIoM9p+zodDl3dMkTfZgdo489+2pN/VBmHfBS2v1BRTNcGAFzC+GfQAqXlLqV9X6acgjI1DfbVDS38dVnDoPO+zt/HoSGdIxUbWCrJobSd+dpX6Kr5ggEA8FIEmVrmNkafbctVUZlRk/q+evW3cQoNqPzH4HQ41CX4mOKCTwaY9APl2pl/vKbKBQDAqxFkatmG3BPKPnxMPg7pr4NjFdHA74L7cDikzmEutQivJ5eRnl2aox+Ly2ugWgAAvBtBphZ9ubdIu34+eSal/2V+an0Rtx45HNLgzpEKDXDo0LETSl6+v1KPfAAAoC4hyNSSn4rLNeXLg5KkHs0bKibk9Em9FyrA10cDmvkp0Nehbw4c087DzJcBAFxaCDK1wBijl744oKJSlxoGOhTfMrza+g4JcOqR+EhJ0jf5J/TT0dJq6xsAAG9HkKkF3xW4tOGHYvn7ONTvMj/5OB3V2v/NHcLUJzZYbiN9vj1Pbi4xAQAuEQSZGnas7IQ25p+QJN3bq4nCLuAOpcpyOBx6ckC0/JxS/pFS7f6ZS0wAgEsDQaaGrdrzk8pcUqvwAP2uS/VdUvq1RvV8dXnTk99vuCn/hA5xFxMA4BJAkKlBecVu7Th4RJI0/qqoar+k9GttGvooIiRA5W7p9fS8Gj0WAADegCBTQ1xuow25J8+KtGnoo44R9Wr8mE6HQwPbNZVD0vLvirR+3+EaPyYAAFYiyNSQJbsK9HOpUYCvU5c3qb1HWjUNCVSrsJO3dr/wyXa53Uz8BQDUXQSZGnC09IRmr8uXJF0Z10gBvjV7SenXujX1VT0/pzb/UKiPNx+o1WMDAFCbCDI1YOYXe/TzcZca+DvUrVlYrR8/yNehEd0bS5JeWrJTx8u4iwkAUDcRZKpZflGJZq/KkiRd0dS3xif4ns3vujTSZWFBOlhYorfT91lSAwAANY0gU81eW7FHJeVudYoIUrMG1g2vv69T469vK0ma+cV3KirhdmwAQN1DkKlGOYeP6f112ZKk+69sKofDmrMxpwzrfpnaNA1W4fFy/feXey2tBQCAmkCQqUbTl+1WucvoqjaNdXl0favLkY/ToSduaCdJ+u9VWTyHCQBQ5xBkqsme/CNa+M0PkqQ//m948AaDOkWoa7NQHStzaeYX31ldDgAA1YogU02mfr5LbiPd0DFC3WLCrC7Hw+Fw6MlBJ4PV/6z5XgcKjltcEQAA1YcgUw22/lCoz7bmyuGQ51KON+nfurH6tGykshNuzVi+2+pyAACoNgSZavD3/2RKkoZdfpnaRTawuJrTnTwr016S9OGGH7T3x6MWVwQAQPUgyFyktXsPaeWuH+XrdGhsQhuryzmrHs0bKqFDU7ncRtOWcVYGAFA3EGQugjHGczbmtl4xah5u/Z1K5/LEDe3kcEiLNx/Q9gNFVpcDAMBFszTIfPnll7r55psVHR0th8OhRYsWVdhujNFzzz2nqKgoBQUFKSEhQbt3e8/ZhC92/aj1+36Wv69Tjw303rMxp3SICtFNXaMlSVM/z7S4GgAALp6lQaa4uFjdunVTSkrKGbe//PLLevXVVzVr1iytXbtW9evX16BBg1RSUlLLlZ7O7Tb6+9KTYWBkfHNFhgZaXFHljEtoIx+nQ8t25Gtj9s9WlwMAwEWxNMgMGTJEL7zwgm655ZbTthljNH36dD377LMaOnSounbtqnfeeUcHDhw47czNL5WWlqqoqKjCUhOWfJurbw8Uqb6/jx65pnWNHKMmtGwSrN9d0UySPEEMAIAL4XK5lJWVpaysLLlc1j6Y2GvnyGRlZSk3N1cJCQmettDQUPXu3Vvp6elnfV1ycrJCQ0M9S0xMTI3U987/Pojx/qtaqlF9/xo5Rk15LKGN/H2cWv3dIa3e85PV5QAAbCY7O1tTFqzWlAWrlZ2dbWktXhtkcnNzJUkREREV2iMiIjzbziQpKUmFhYWeJScnp0bqe2tUL/3Xb9rr/qviaqT/mnRZWJD+X+9YSdLf/pMpY4zFFQEA7CasSaTCmkRaXYb3BpmqCggIUEhISIWlJtTz99WDV7dSg0C/Gum/pv3h2lYK8vPRN9kFStuRb3U5AABUidcGmcjIkykvLy+vQnteXp5nm5V+eX3QG64RXqimDQI1ql8LSSe/0M/t5qwMAMB+vDbIxMXFKTIyUmlpaZ62oqIirV27VvHx8RZWdtKp64Ozv9rrFdcIq+Khq1uqQYCvduYe0SdbD1pdDgAAF8zSIHP06FFt2rRJmzZtknRygu+mTZuUnZ0th8OhsWPH6oUXXtDHH3+srVu36u6771Z0dLSGDRtmZdkeYU0iFR4V4xXXCKsirJ6/Hry6pSRp+ue7dMLltrgiAAAujKVBZsOGDerevbu6d+8uSRo/fry6d++u5557TpL0pz/9SWPGjNGDDz6oXr166ejRo1qyZIkCA+3xnS12cE//ODWq76+9PxVrwcb9VpcDAMAFsTTIXHPNNTLGnLbMmTNH0smHHU6aNEm5ubkqKSnRsmXL1LZtWytLrnOCA3z1h2taSZJeSdut0hP2musDALi0ee0cGTtxu13Kycnxuom/lZ2QfGef5ooMCdT+guOau9Z+c30AAJcugkw1KDqUr7dWbPe6ib+VnZAc6Oejx647+ayoV9N2q/B4eW2WCQBAlRFkqklI4wivnPhb2QnJt/VspjZNg/XzsXKlrNhTS9UBAHBxCDKQJPn6OPVfv+kgSZrz9T7lHD5mcUUAAJwfQQYe17Rrov6tG6vM5dbkf++0uhwAAM6LIAMPh8OhZ27sIKdD+nTrQa3+jgdKAgC8G0EGFXSICtGdfZpLkiZ+9K3K+ZI8AIAXI8jgNE9c306N6vtrd/5Rvb16n9XlAABwVgSZS0xlvlsmtJ6fnhrcTpI0fdluHSw8XttlAgBQKQSZS0xlv1vm1h4x6h4bpqOlJzRh0TYZw9OxAQDehyBzCarMd8s4nQ69lNhVfj4OLduRr0+28HRsAID3IcjgrNpGNNAfrmktSXr+42/1c3GZxRUBAFARQQbn9IdrW6lN02AdKi7TM4u2cokJAOBVCDI4pwBfH025rZt8nQ59tjVX/8z4weqSAADwIMjgvLo2C9P4G9pKOnmJad9PxRZXBADASQQZVMpDV7fSlXGNVFzm0qPvb1RJ+em3bQMAUNsIMqgUH6dD039/uRrV99e2/UV6ZiG3ZAMArEeQQaVFhwVpxh3d5XRI/9r4g95d873VJQEALnEEGVyQfq0b66nB7SVJzy/erhWZ+RZXBAC4lBFkcMEevLqlhne/TC630R/e3ajNOQVWlwQAuEQRZHDBHA6HJid21VVtGut4uUv3zlmv3XlHrC4LAHAJIsigSvx9nZp5Zw91vixEh4rLdPsba5SZS5gBANQuggyqLDjAV+/e1/sXYSZdW34osLosAMAlhCCDixJWz1/v3ddH3ZqF6udj5brtH+laso0HTAIAagdBBhcttJ6f3r2/t65p10Ql5W49/O5GTV+2Sy433zMDAKhZBBlUiwaBfvrvu3tqVN8WkqTpy3brjjfWaH/BcWsLAwDUaQQZVBtfH6ee/20nTft9N9X399G6fYc1aNqXemtVlk643FaXBwCogwgyqHa3dG+mzx6/St1jw3S09IQmfbJdN81YpWXb83isAQCgWhFkUCOah9fXvx7uq7/e0kWhQX7amXtE97+zQUNTvtbizQdUdoIzNACAi+drdQGwnsvlUnZ2tmc9NjZWPj4+F92v0+nQ/+sdq8GdI/XGl3v19up92vJDoca8/42aNAjQ8O6X6cauUepyWagcDsdFHw8AcOmxRZBJSUnR3/72N+Xm5qpbt26aMWOGrrzySqvLqjOys7M1ZcFqhTWJVMGPuXpiuBQXF1dt/Teq76+nh7TX/VfF6Z307/X+umz9eKRU//hyr/7x5V5dFhakq9o0Vt/WjdX1slDFNqonp5NgAwBWcLuNjpW7dLTkhI6WlutIyQkdK3OpzOWWy2V0wm10MLdIWYUuGSN9tvNnDQ5uolZNgi2p1+uDzAcffKDx48dr1qxZ6t27t6ZPn65BgwYpMzNTTZs2tbq8OiOsSaTCo2Jq9BiNgwM0/vq2GjOwtZZtz9MnWw4qbWee9hcc17z1OZq3PkfSyS/a6xgVoo7RIWrVpL6iw4JOLqFBCgny5ewNAPyKy210rOxk4DhW5lJx6QkdLT3h+fNIyck/j57689c//2K9uOyELmQ64+oDB9UovDFB5mymTp2qBx54QPfcc48kadasWfr000/11ltv6emnn7a4OlSFn49TQ7pEaUiXKB0rO6G1WYf11a6ftOH7w9qZe0RHS09o3b7DWrfv8GmvDfLzUVg9P4UG+Skk6OSf9f19FODro0A/pwL8fBTg6/zfxUc+ToecDsnH6ZDD4ZDT4ZCPUxV+djpObnNIupCMdPIVF7D/Beav6o5rlfm9VJlfXuY8PVWuj8rUUj0Tw8/XzfneT2X6qPQ+59/lvO+7UqNSDZ/jyVqq5VC19xlUopbKdHS+PSr396FyxznhMipzuXXCZVTucqvc7Vb5CaMTbvfJ9f9tP+EyOl7u0rGyEzpe5lJxmUvHy06uF5e5amTeoY/ToeAAX8/i5+uQj9MpP6dD5WWlyisqkUNSi/B6igwNrPbjV5ZXB5mysjJlZGQoKSnJ0+Z0OpWQkKD09PQzvqa0tFSlpaWe9cLCQklSUVFRtdZ25MgR5efsVenxYv10IEdO/0AF+Pqo8Kc87dxZJknKz/lBpceLq72tNo535EjtPTcpXNKw5tKw5iFyuRoop7BM3x0u0d5Dpco7Wq4fi08uRSVuFZdKxUel/bVWHQDYh9MhBfg6FeTrUJC/U/X9nAry81E9P6eC/J2q5+dUPT8f1fN3KMjPqXq+TtXz91E9f6eCfJ0n//TzUX1/h/z+9z+AZ7J/f6EWbvxBkvRo/95qERVY7f/OnurvvKHQeLH9+/cbSWb16tUV2p988klz5ZVXnvE1EydONDoZdFlYWFhYWFhsvuTk5JwzK3j1GZmqSEpK0vjx4z3rbrdbhw8fVnh4uBwOh4qKihQTE6OcnByFhIRYWOmlhXG3BuNe+xhzazDu1qjJcTfG6MiRI4qOjj7nfl4dZBo3biwfHx/l5eVVaM/Ly1NkZOQZXxMQEKCAgIAKbWFhYaftFxISwl92CzDu1mDcax9jbg3G3Ro1Ne6hoaHn3cervxDP399fPXr0UFpamqfN7XYrLS1N8fHxFlYGAAC8gVefkZGk8ePHa+TIkerZs6euvPJKTZ8+XcXFxZ67mAAAwKXL64PM73//e/3444967rnnlJubq8svv1xLlixRRERElfoLCAjQxIkTT7v8hJrFuFuDca99jLk1GHdreMO4O4zhKX4AAMCevHqODAAAwLkQZAAAgG0RZAAAgG0RZAAAgG1dUkEmJSVFLVq0UGBgoHr37q1169ZZXVKdkpycrF69eqlBgwZq2rSphg0bpszMzAr7lJSUaPTo0QoPD1dwcLASExNP+8JDVN3kyZPlcDg0duxYTxtjXnP279+vO++8U+Hh4QoKClKXLl20YcMGz3ZjjJ577jlFRUUpKChICQkJ2r17t4UV25/L5dKECRMUFxenoKAgtWrVSn/5y18qPI+Hcb94X375pW6++WZFR0fL4XBo0aJFFbZXZowPHz6sESNGKCQkRGFhYbrvvvt09OjR6i/24p+IZA/z5s0z/v7+5q233jLffvuteeCBB0xYWJjJy8uzurQ6Y9CgQSY1NdVs27bNbNq0yfzmN78xsbGx5ujRo559Hn74YRMTE2PS0tLMhg0bTJ8+fUzfvn0trLruWLdunWnRooXp2rWrefzxxz3tjHnNOHz4sGnevLkZNWqUWbt2rdm7d69ZunSp2bNnj2efyZMnm9DQULNo0SKzefNm89vf/tbExcWZ48ePW1i5vb344osmPDzcfPLJJyYrK8vMnz/fBAcHm1deecWzD+N+8T777DPzzDPPmAULFhhJZuHChRW2V2aMBw8ebLp162bWrFljvvrqK9O6dWtzxx13VHutl0yQufLKK83o0aM96y6Xy0RHR5vk5GQLq6rb8vPzjSSzcuVKY4wxBQUFxs/Pz8yfP9+zz44dO4wkk56eblWZdcKRI0dMmzZtzOeff24GDBjgCTKMec156qmnTP/+/c+63e12m8jISPO3v/3N01ZQUGACAgLM+++/Xxsl1kk33nijuffeeyu0DR8+3IwYMcIYw7jXhF8HmcqM8fbt240ks379es8+//73v43D4TD79++v1vouiUtLZWVlysjIUEJCgqfN6XQqISFB6enpFlZWtxUWFkqSGjVqJEnKyMhQeXl5hc+hffv2io2N5XO4SKNHj9aNN95YYWwlxrwmffzxx+rZs6duvfVWNW3aVN27d9ebb77p2Z6VlaXc3NwKYx8aGqrevXsz9hehb9++SktL065duyRJmzdv1qpVqzRkyBBJjHttqMwYp6enKywsTD179vTsk5CQIKfTqbVr11ZrPV7/zb7V4aeffpLL5Trt24AjIiK0c+dOi6qq29xut8aOHat+/fqpc+fOkqTc3Fz5+/uf9hDPiIgI5ebmWlBl3TBv3jxt3LhR69evP20bY15z9u7dq5kzZ2r8+PH6r//6L61fv16PPfaY/P39NXLkSM/4nun3DmNfdU8//bSKiorUvn17+fj4yOVy6cUXX9SIESMkiXGvBZUZ49zcXDVt2rTCdl9fXzVq1KjaP4dLIsig9o0ePVrbtm3TqlWrrC6lTsvJydHjjz+uzz//XIGBgVaXc0lxu93q2bOn/vrXv0qSunfvrm3btmnWrFkaOXKkxdXVXR9++KHee+89zZ07V506ddKmTZs0duxYRUdHM+6XqEvi0lLjxo3l4+Nz2p0aeXl5ioyMtKiquuvRRx/VJ598ohUrVqhZs2ae9sjISJWVlamgoKDC/nwOVZeRkaH8/HxdccUV8vX1la+vr1auXKlXX31Vvr6+ioiIYMxrSFRUlDp27FihrUOHDsrOzpYkz/jye6d6Pfnkk3r66ad1++23q0uXLrrrrrs0btw4JScnS2Lca0NlxjgyMlL5+fkVtp84cUKHDx+u9s/hkggy/v7+6tGjh9LS0jxtbrdbaWlpio+Pt7CyusUYo0cffVQLFy7U8uXLFRcXV2F7jx495OfnV+FzyMzMVHZ2Np9DFV133XXaunWrNm3a5Fl69uypESNGeH5mzGtGv379Tvt6gV27dql58+aSpLi4OEVGRlYY+6KiIq1du5axvwjHjh2T01nxny4fHx+53W5JjHttqMwYx8fHq6CgQBkZGZ59li9fLrfbrd69e1dvQdU6ddiLzZs3zwQEBJg5c+aY7du3mwcffNCEhYWZ3Nxcq0urMx555BETGhpqvvjiC3Pw4EHPcuzYMc8+Dz/8sImNjTXLly83GzZsMPHx8SY+Pt7CquueX961ZAxjXlPWrVtnfH19zYsvvmh2795t3nvvPVOvXj3z7rvvevaZPHmyCQsLMx999JHZsmWLGTp0KLcBX6SRI0eayy67zHP79YIFC0zjxo3Nn/70J88+jPvFO3LkiPnmm2/MN998YySZqVOnmm+++cZ8//33xpjKjfHgwYNN9+7dzdq1a82qVatMmzZtuP36Ys2YMcPExsYaf39/c+WVV5o1a9ZYXVKdIumMS2pqqmef48ePmz/84Q+mYcOGpl69euaWW24xBw8etK7oOujXQYYxrzmLFy82nTt3NgEBAaZ9+/bmjTfeqLDd7XabCRMmmIiICBMQEGCuu+46k5mZaVG1dUNRUZF5/PHHTWxsrAkMDDQtW7Y0zzzzjCktLfXsw7hfvBUrVpzx9/nIkSONMZUb40OHDpk77rjDBAcHm5CQEHPPPfeYI0eOVHutDmN+8XWIAAAANnJJzJEBAAB1E0EGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEG8BIOh0OLFi26qD5GjRqlYcOGedavueYajR079qL6lKTnn39el19++UX342327dsnh8OhTZs2WV0KgCoiyAC14Mcff9Qjjzyi2NhYBQQEKDIyUoMGDdLXX3/t2efgwYMaMmTIRR3nlVde0Zw5cy6y2tP98Y9/rPCAuF8HpqqqzYBUXTUD8C6+VhcAXAoSExNVVlamt99+Wy1btlReXp7S0tJ06NAhzz7V8Wj70NDQi+7jl4wxcrlcCg4OVnBwcLX2XZeVlZXJ39/f6jKAS0O1P70JQAU///yzkWS++OKLc+4nySxcuNAYY0xWVpaRZD744APTv39/ExgYaHr27GkyMzPNunXrTI8ePUz9+vXN4MGDTX5+vqePkSNHmqFDh3rWf/0AyXfeecf06NHDBAcHm4iICHPHHXeYvLw8z/ZTD4r77LPPzBVXXGH8/PzMihUrzMSJE023bt2MMcZMnDjxtAfJrVixwlx77bVm9OjRFd5Tfn6+8fPzM8uWLTvt/aampp71AaPff/+9+e1vf2vq169vGjRoYG699dbzPql+y5Yt5tprrzWBgYGmUaNG5oEHHvA8oO5sNZ8a53/961/mmmuuMUFBQaZr165m9erVFfr+6quvPJ9Ds2bNzJgxY8zRo0c925s3b24mTZpk7rrrLtOgQQPPg/V+bcCAAWbMmDHmySefNA0bNjQRERFm4sSJFfaZMmWK6dy5s6lXr55p1qyZeeSRRyo8aC81NdWEhoaaxYsXm7Zt25qgoCCTmJhoiouLzZw5c0zz5s1NWFiYGTNmjDlx4oTndSUlJeaJJ54w0dHRpl69eubKK680K1as8Gzft2+fuemmm0xYWJipV6+e6dixo/n000/POeaANyDIADWsvLzcBAcHm7Fjx5qSkpKz7nemINO+fXuzZMkSs337dtOnTx/To0cPc80115hVq1aZjRs3mtatW5uHH37Y08f5gszs2bPNZ599Zr777juTnp5u4uPjzZAhQzzbTwWZrl27mv/85z9mz5495tChQxWCzJEjR8xtt91mBg8ebA4ePGgOHjxoSktLzXvvvWcaNmxY4T1OnTrVtGjRwrjd7tPe77Fjx8wTTzxhOnXq5Onn2LFjxuVymcsvv9z079/fbNiwwaxZs8b06NHDDBgw4Kxjd/ToURMVFWWGDx9utm7datLS0kxcXJwnUJyt5l+O8yeffGIyMzPN7373O9O8eXNTXl5ujDFmz549pn79+mbatGlm165d5uuvvzbdu3c3o0aN8hy/efPmJiQkxPz97383e/bsMXv27DljnQMGDDAhISHm+eefN7t27TJvv/22cTgc5j//+Y9nn2nTppnly5ebrKwsk5aWZtq1a2ceeeQRz/bU1FTj5+dnrr/+erNx40azcuVKEx4ebm644QZz2223mW+//dYsXrzY+Pv7m3nz5nled//995u+ffuaL7/80uzZs8f87W9/MwEBAWbXrl3GGGNuvPFGc/3115stW7aY7777zixevNisXLnyrGMOeAuCDFAL/vnPf5qGDRuawMBA07dvX5OUlGQ2b95cYZ8zBZn//u//9mx///33jSSTlpbmaUtOTjbt2rXzrJ8vyPza+vXrjSTP//hPBZlFixZV2O+XQeZMxzHGmOPHj5uGDRuaDz74wNPWtWtX8/zzz5/1+L/u1xhj/vOf/xgfHx+TnZ3tafv222+NJLNu3boz9vPGG2+Yhg0bVjhL8umnnxqn0+k5k3Omms80zqeOtWPHDmOMMffdd5958MEHK7zuq6++Mk6n0xw/ftwYczLIDBs27Kzv85QBAwaY/v37V2jr1auXeeqpp876mvnz55vw8HDP+qkzWb8MSw899JCpV69ehTM3gwYNMg899JAx5uQZLh8fH7N///4KfV933XUmKSnJGGNMly5dzvlZAd6Kyb5ALUhMTNSBAwf08ccfa/Dgwfriiy90xRVXnHdibteuXT0/R0RESJK6dOlSoS0/P7/SdWRkZOjmm29WbGysGjRooAEDBkiSsrOzK+zXs2fPSvd5SmBgoO666y699dZbkqSNGzdq27ZtGjVq1AX1s2PHDsXExCgmJsbT1rFjR4WFhWnHjh1nfU23bt1Uv359T1u/fv3kdruVmZl53mP+cpyjoqIkyTOumzdv1pw5czzzhIKDgzVo0CC53W5lZWV5XlfZMfvlsU4d75ef4bJly3TdddfpsssuU4MGDXTXXXfp0KFDOnbsmGefevXqqVWrVp71iIgItWjRosI8pl/+3di6datcLpfatm1b4X2sXLlS3333nSTpscce0wsvvKB+/fpp4sSJ2rJlS6XeD2A1ggxQSwIDA3X99ddrwoQJWr16tUaNGqWJEyee8zV+fn6enx0Oxxnb3G53pY5fXFysQYMGKSQkRO+9957Wr1+vhQsXSjo5OfWXfhkILsT999+vzz//XD/88INSU1M1cOBANW/evEp91aYzjfOpcT169Kgeeughbdq0ybNs3rxZu3fvrhAmKjtmvzzWqeOdOta+fft00003qWvXrvrXv/6ljIwMpaSkSKr4GZ2pj3P1e/ToUfn4+CgjI6PC+9ixY4deeeUVSSc/u7179+quu+7S1q1b1bNnT82YMaNS7wmwEnctARbp2LHjRX9vzIXYuXOnDh06pMmTJ3vOdmzYsKFKffn7+8vlcp3W3qVLF/Xs2VNvvvmm5s6dq9dee+2C++nQoYNycnKUk5PjqXP79u0qKChQx44dz9hPhw4dNGfOHBUXF3sCxddffy2n06l27dqds+bzueKKK7R9+3a1bt36gl97oTIyMuR2uzVlyhQ5nSf/n/nhhx9edL/du3eXy+VSfn6+rrrqqrPuFxMTo4cfflgPP/ywkpKS9Oabb2rMmDEXfXygJnFGBqhhhw4d0sCBA/Xuu+9qy5YtysrK0vz58/Xyyy9r6NChtVZHbGys/P39NWPGDO3du1cff/yx/vKXv1SprxYtWmjLli3KzMzUTz/9pPLycs+2+++/X5MnT5YxRrfccst5+8nKytKmTZv0008/qbS0VAkJCerSpYtGjBihjRs3at26dbr77rs1YMCAs16+GTFihAIDAzVy5Eht27ZNK1as0JgxY3TXXXd5Lsmdq+Zzeeqpp7R69Wo9+uij2rRpk3bv3q2PPvpIjz76aCVHq/Jat26t8vJyz2f0P//zP5o1a9ZF99u2bVuNGDFCd999txYsWKCsrCytW7dOycnJ+vTTTyVJY8eO1dKlS5WVlaWNGzdqxYoV6tChw0UfG6hpBBmghgUHB6t3796aNm2arr76anXu3FkTJkzQAw88cN4zFtWpSZMmmjNnjubPn6+OHTtq8uTJ+vvf/16lvh544AG1a9dOPXv2VJMmTSp8sd8dd9whX19f3XHHHQoMDDxnP4mJiRo8eLCuvfZaNWnSRO+//74cDoc++ugjNWzYUFdffbUSEhLUsmVLffDBB2ftp169elq6dKkOHz6sXr166Xe/+52uu+66CuN7rprPpWvXrlq5cqV27dqlq666St27d9dzzz2n6OjoSr3+QnTr1k1Tp07VSy+9pM6dO+u9995TcnJytfSdmpqqu+++W0888YTatWunYcOGaf369YqNjZUkuVwujR49Wh06dNDgwYPVtm1bvf7669VybKAmOYwxxuoiANQd+/btU6tWrbR+/XpdccUVVpcDoI4jyACoFuXl5Tp06JD++Mc/Kisrq9JnPADgYnBpCUC1+PrrrxUVFaX169dXy7wOAKgMzsgAAADb4owMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwrf8PNb1l3JuEDnMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the result of this using seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(academy_csvs_df['Similarity to other names'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>trainer</th>\n",
       "      <th>Analytic_W1</th>\n",
       "      <th>Independent_W1</th>\n",
       "      <th>Determined_W1</th>\n",
       "      <th>Professional_W1</th>\n",
       "      <th>Studious_W1</th>\n",
       "      <th>Imaginative_W1</th>\n",
       "      <th>Analytic_W2</th>\n",
       "      <th>Independent_W2</th>\n",
       "      <th>...</th>\n",
       "      <th>Professional_W9</th>\n",
       "      <th>Studious_W9</th>\n",
       "      <th>Imaginative_W9</th>\n",
       "      <th>Analytic_W10</th>\n",
       "      <th>Independent_W10</th>\n",
       "      <th>Determined_W10</th>\n",
       "      <th>Professional_W10</th>\n",
       "      <th>Studious_W10</th>\n",
       "      <th>Imaginative_W10</th>\n",
       "      <th>Similarity to other names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>CHAIM INSEAL</td>\n",
       "      <td>MOHAMMAD VELAZQUEZ</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>GERTRUDA SYDDIE</td>\n",
       "      <td>MOHAMMAD VELAZQUEZ</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>GODFRY SEPHTON</td>\n",
       "      <td>MOHAMMAD VELAZQUEZ</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GUSTAF LUDE</td>\n",
       "      <td>GREGOR GOMEZ</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LYNNETT SWIN</td>\n",
       "      <td>GREGOR GOMEZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>MORITZ MOSEDALL</td>\n",
       "      <td>MOHAMMAD VELAZQUEZ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUINTUS PENELLA</td>\n",
       "      <td>GREGOR GOMEZ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIMON MURREY</td>\n",
       "      <td>GREGOR GOMEZ</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>THOM DERWIN</td>\n",
       "      <td>MOHAMMAD VELAZQUEZ</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOLANDA FOSSE</td>\n",
       "      <td>GREGOR GOMEZ</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name             trainer  Analytic_W1  Independent_W1   \n",
       "393     CHAIM INSEAL  MOHAMMAD VELAZQUEZ            1               3  \\\n",
       "394  GERTRUDA SYDDIE  MOHAMMAD VELAZQUEZ            3               1   \n",
       "396   GODFRY SEPHTON  MOHAMMAD VELAZQUEZ            4               2   \n",
       "2        GUSTAF LUDE        GREGOR GOMEZ            6               4   \n",
       "4       LYNNETT SWIN        GREGOR GOMEZ            2               2   \n",
       "392  MORITZ MOSEDALL  MOHAMMAD VELAZQUEZ            1               1   \n",
       "0    QUINTUS PENELLA        GREGOR GOMEZ            1               2   \n",
       "1       SIMON MURREY        GREGOR GOMEZ            6               1   \n",
       "395      THOM DERWIN  MOHAMMAD VELAZQUEZ            3               7   \n",
       "3      YOLANDA FOSSE        GREGOR GOMEZ            2               1   \n",
       "\n",
       "     Determined_W1  Professional_W1  Studious_W1  Imaginative_W1  Analytic_W2   \n",
       "393              3                4            1               2          3.0  \\\n",
       "394              2                8            1               4          2.0   \n",
       "396              5                1            1               2          4.0   \n",
       "2                1                1            2               3          1.0   \n",
       "4                4                5            1               2          3.0   \n",
       "392              5                1            2               6          5.0   \n",
       "0                2                1            2               2          NaN   \n",
       "1                1                2            4               2          3.0   \n",
       "395              3                3            3               1          2.0   \n",
       "3                2                3            3               3          4.0   \n",
       "\n",
       "     Independent_W2  ...  Professional_W9  Studious_W9  Imaginative_W9   \n",
       "393             3.0  ...              NaN          NaN             NaN  \\\n",
       "394             4.0  ...              NaN          NaN             NaN   \n",
       "396             1.0  ...              NaN          NaN             NaN   \n",
       "2               1.0  ...              NaN          NaN             NaN   \n",
       "4               2.0  ...              NaN          NaN             NaN   \n",
       "392             3.0  ...              NaN          NaN             NaN   \n",
       "0               NaN  ...              NaN          NaN             NaN   \n",
       "1               1.0  ...              NaN          NaN             NaN   \n",
       "395             7.0  ...              NaN          NaN             NaN   \n",
       "3               2.0  ...              NaN          NaN             NaN   \n",
       "\n",
       "     Analytic_W10  Independent_W10  Determined_W10  Professional_W10   \n",
       "393           NaN              NaN             NaN               NaN  \\\n",
       "394           NaN              NaN             NaN               NaN   \n",
       "396           NaN              NaN             NaN               NaN   \n",
       "2             NaN              NaN             NaN               NaN   \n",
       "4             NaN              NaN             NaN               NaN   \n",
       "392           NaN              NaN             NaN               NaN   \n",
       "0             NaN              NaN             NaN               NaN   \n",
       "1             NaN              NaN             NaN               NaN   \n",
       "395           NaN              NaN             NaN               NaN   \n",
       "3             NaN              NaN             NaN               NaN   \n",
       "\n",
       "     Studious_W10  Imaginative_W10  Similarity to other names  \n",
       "393           NaN              NaN                        100  \n",
       "394           NaN              NaN                        100  \n",
       "396           NaN              NaN                        100  \n",
       "2             NaN              NaN                        100  \n",
       "4             NaN              NaN                        100  \n",
       "392           NaN              NaN                        100  \n",
       "0             NaN              NaN                        100  \n",
       "1             NaN              NaN                        100  \n",
       "395           NaN              NaN                        100  \n",
       "3             NaN              NaN                        100  \n",
       "\n",
       "[10 rows x 65 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing table of names with similarity to other names above 80\n",
    "\n",
    "academy_csvs_df[academy_csvs_df['Similarity to other names'] > 80].sort_values('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since none of these are similar to eachother, we will assume no duplicate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the names to upper case for consistency\n",
    "\n",
    "academy_csvs_df['name'] = academy_csvs_df['name'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GREGOR GOMEZ', 'BRUCE LUGO', 'NEIL MCCARTHY', 'RACHEL RICHARD',\n",
       "       'HAMZAH MELIA', 'BURHAN MILNER', 'ELLY KELLY', 'TRIXIE ORANGE',\n",
       "       'JOHN SANDBOX', 'EDWARD REINHART', 'LUCY FOSTER',\n",
       "       'GINA CARTWRIGHT', 'ESHAL BRANDT', 'MACEY BROUGHTON',\n",
       "       'IGOR COATES', 'MOHAMMAD VELAZQUEZ', 'MARTINA MEADOWS'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking names of trainers for misspellings\n",
    "\n",
    "academy_csvs_df['trainer'].unique()\n",
    "\n",
    "# It seems Ely Kely is actually Elly Kelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GREGOR GOMEZ', 'BRUCE LUGO', 'NEIL MCCARTHY', 'RACHEL RICHARD',\n",
       "       'HAMZAH MELIA', 'BURHAN MILNER', 'ELLY KELLY', 'TRIXIE ORANGE',\n",
       "       'JOHN SANDBOX', 'EDWARD REINHART', 'LUCY FOSTER',\n",
       "       'GINA CARTWRIGHT', 'ESHAL BRANDT', 'MACEY BROUGHTON',\n",
       "       'IGOR COATES', 'MOHAMMAD VELAZQUEZ', 'MARTINA MEADOWS'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing Ely Kely in trainers with Elly Kelly\n",
    "\n",
    "academy_csvs_df['trainer'].replace('Ely Kely', 'Elly Kelly', inplace=True)\n",
    "\n",
    "academy_csvs_df['trainer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if Ely Kely was once a trainee (but her actual name is Elly Kelly)\n",
    "len(academy_csvs_df[academy_csvs_df['name'] == 'Ely Kely'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the trainer to upper case for consistency\n",
    "\n",
    "academy_csvs_df['trainer'] = academy_csvs_df['trainer'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_minus_names = academy_csvs_df.iloc[0:, 2:]\n",
    "df_minus_names = df_minus_names.drop(['Cohort Name', 'Cohort Date'], axis=1)\n",
    "\n",
    "non_whole_values = df_minus_names.mod(1) != 0\n",
    "\n",
    "(df_minus_names.isna().sum() == non_whole_values.sum()).sum() / len(df_minus_names.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>trainer</th>\n",
       "      <th>Analytic_W1</th>\n",
       "      <th>Independent_W1</th>\n",
       "      <th>Determined_W1</th>\n",
       "      <th>Professional_W1</th>\n",
       "      <th>Studious_W1</th>\n",
       "      <th>Imaginative_W1</th>\n",
       "      <th>Analytic_W2</th>\n",
       "      <th>Independent_W2</th>\n",
       "      <th>...</th>\n",
       "      <th>Professional_W9</th>\n",
       "      <th>Studious_W9</th>\n",
       "      <th>Imaginative_W9</th>\n",
       "      <th>Analytic_W10</th>\n",
       "      <th>Independent_W10</th>\n",
       "      <th>Determined_W10</th>\n",
       "      <th>Professional_W10</th>\n",
       "      <th>Studious_W10</th>\n",
       "      <th>Imaginative_W10</th>\n",
       "      <th>Similarity to other names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUINTUS PENELLA</td>\n",
       "      <td>GREGOR GOMEZ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIMON MURREY</td>\n",
       "      <td>GREGOR GOMEZ</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GUSTAF LUDE</td>\n",
       "      <td>GREGOR GOMEZ</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOLANDA FOSSE</td>\n",
       "      <td>GREGOR GOMEZ</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LYNNETT SWIN</td>\n",
       "      <td>GREGOR GOMEZ</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>MORITZ MOSEDALL</td>\n",
       "      <td>MOHAMMAD VELAZQUEZ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>CHAIM INSEAL</td>\n",
       "      <td>MOHAMMAD VELAZQUEZ</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>GERTRUDA SYDDIE</td>\n",
       "      <td>MOHAMMAD VELAZQUEZ</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>THOM DERWIN</td>\n",
       "      <td>MOHAMMAD VELAZQUEZ</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>GODFRY SEPHTON</td>\n",
       "      <td>MOHAMMAD VELAZQUEZ</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name             trainer  Analytic_W1  Independent_W1   \n",
       "0    QUINTUS PENELLA        GREGOR GOMEZ            1               2  \\\n",
       "1       SIMON MURREY        GREGOR GOMEZ            6               1   \n",
       "2        GUSTAF LUDE        GREGOR GOMEZ            6               4   \n",
       "3      YOLANDA FOSSE        GREGOR GOMEZ            2               1   \n",
       "4       LYNNETT SWIN        GREGOR GOMEZ            2               2   \n",
       "..               ...                 ...          ...             ...   \n",
       "392  MORITZ MOSEDALL  MOHAMMAD VELAZQUEZ            1               1   \n",
       "393     CHAIM INSEAL  MOHAMMAD VELAZQUEZ            1               3   \n",
       "394  GERTRUDA SYDDIE  MOHAMMAD VELAZQUEZ            3               1   \n",
       "395      THOM DERWIN  MOHAMMAD VELAZQUEZ            3               7   \n",
       "396   GODFRY SEPHTON  MOHAMMAD VELAZQUEZ            4               2   \n",
       "\n",
       "     Determined_W1  Professional_W1  Studious_W1  Imaginative_W1  Analytic_W2   \n",
       "0                2                1            2               2          NaN  \\\n",
       "1                1                2            4               2          3.0   \n",
       "2                1                1            2               3          1.0   \n",
       "3                2                3            3               3          4.0   \n",
       "4                4                5            1               2          3.0   \n",
       "..             ...              ...          ...             ...          ...   \n",
       "392              5                1            2               6          5.0   \n",
       "393              3                4            1               2          3.0   \n",
       "394              2                8            1               4          2.0   \n",
       "395              3                3            3               1          2.0   \n",
       "396              5                1            1               2          4.0   \n",
       "\n",
       "     Independent_W2  ...  Professional_W9  Studious_W9  Imaginative_W9   \n",
       "0               NaN  ...              NaN          NaN             NaN  \\\n",
       "1               1.0  ...              NaN          NaN             NaN   \n",
       "2               1.0  ...              NaN          NaN             NaN   \n",
       "3               2.0  ...              NaN          NaN             NaN   \n",
       "4               2.0  ...              NaN          NaN             NaN   \n",
       "..              ...  ...              ...          ...             ...   \n",
       "392             3.0  ...              NaN          NaN             NaN   \n",
       "393             3.0  ...              NaN          NaN             NaN   \n",
       "394             4.0  ...              NaN          NaN             NaN   \n",
       "395             7.0  ...              NaN          NaN             NaN   \n",
       "396             1.0  ...              NaN          NaN             NaN   \n",
       "\n",
       "     Analytic_W10  Independent_W10  Determined_W10  Professional_W10   \n",
       "0             NaN              NaN             NaN               NaN  \\\n",
       "1             NaN              NaN             NaN               NaN   \n",
       "2             NaN              NaN             NaN               NaN   \n",
       "3             NaN              NaN             NaN               NaN   \n",
       "4             NaN              NaN             NaN               NaN   \n",
       "..            ...              ...             ...               ...   \n",
       "392           NaN              NaN             NaN               NaN   \n",
       "393           NaN              NaN             NaN               NaN   \n",
       "394           NaN              NaN             NaN               NaN   \n",
       "395           NaN              NaN             NaN               NaN   \n",
       "396           NaN              NaN             NaN               NaN   \n",
       "\n",
       "     Studious_W10  Imaginative_W10  Similarity to other names  \n",
       "0             NaN              NaN                        100  \n",
       "1             NaN              NaN                        100  \n",
       "2             NaN              NaN                        100  \n",
       "3             NaN              NaN                        100  \n",
       "4             NaN              NaN                        100  \n",
       "..            ...              ...                        ...  \n",
       "392           NaN              NaN                        100  \n",
       "393           NaN              NaN                        100  \n",
       "394           NaN              NaN                        100  \n",
       "395           NaN              NaN                        100  \n",
       "396           NaN              NaN                        100  \n",
       "\n",
       "[397 rows x 65 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academy_csvs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                          object\n",
       "trainer                       object\n",
       "Analytic_W1                    int64\n",
       "Independent_W1                 int64\n",
       "Determined_W1                  int64\n",
       "                              ...   \n",
       "Determined_W10               float64\n",
       "Professional_W10             float64\n",
       "Studious_W10                 float64\n",
       "Imaginative_W10              float64\n",
       "Similarity to other names      int64\n",
       "Length: 65, dtype: object"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academy_csvs_df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to clean academy_csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_academy_csvs_df(df):\n",
    "\n",
    "    df['name'] = df['name'].str.strip().upper()\n",
    "\n",
    "    df['trainer'].replace('Ely Kely', 'Elly Kelly', inplace=True)\n",
    "    \n",
    "    df['trainer'] = df['trainer'].str.upper()\n",
    "\n",
    "    df[['Analytic_W1', 'Independent_W1', 'Determined_W1', 'Professional_W1',\n",
    "       'Studious_W1', 'Imaginative_W1', 'Analytic_W2', 'Independent_W2',\n",
    "       'Determined_W2', 'Professional_W2', 'Studious_W2', 'Imaginative_W2',\n",
    "       'Analytic_W3', 'Independent_W3', 'Determined_W3', 'Professional_W3',\n",
    "       'Studious_W3', 'Imaginative_W3', 'Analytic_W4', 'Independent_W4',\n",
    "       'Determined_W4', 'Professional_W4', 'Studious_W4', 'Imaginative_W4',\n",
    "       'Analytic_W5', 'Independent_W5', 'Determined_W5', 'Professional_W5',\n",
    "       'Studious_W5', 'Imaginative_W5', 'Analytic_W6', 'Independent_W6',\n",
    "       'Determined_W6', 'Professional_W6', 'Studious_W6', 'Imaginative_W6',\n",
    "       'Analytic_W7', 'Independent_W7', 'Determined_W7', 'Professional_W7',\n",
    "       'Studious_W7', 'Imaginative_W7', 'Analytic_W8', 'Independent_W8',\n",
    "       'Determined_W8', 'Professional_W8', 'Studious_W8', 'Imaginative_W8',\n",
    "       'Analytic_W9', 'Independent_W9', 'Determined_W9', 'Professional_W9',\n",
    "       'Studious_W9', 'Imaginative_W9', 'Analytic_W10', 'Independent_W10',\n",
    "       'Determined_W10', 'Professional_W10', 'Studious_W10', 'Imaginative_W10']] = df[['Analytic_W1', 'Independent_W1', 'Determined_W1', 'Professional_W1',\n",
    "       'Studious_W1', 'Imaginative_W1', 'Analytic_W2', 'Independent_W2',\n",
    "       'Determined_W2', 'Professional_W2', 'Studious_W2', 'Imaginative_W2',\n",
    "       'Analytic_W3', 'Independent_W3', 'Determined_W3', 'Professional_W3',\n",
    "       'Studious_W3', 'Imaginative_W3', 'Analytic_W4', 'Independent_W4',\n",
    "       'Determined_W4', 'Professional_W4', 'Studious_W4', 'Imaginative_W4',\n",
    "       'Analytic_W5', 'Independent_W5', 'Determined_W5', 'Professional_W5',\n",
    "       'Studious_W5', 'Imaginative_W5', 'Analytic_W6', 'Independent_W6',\n",
    "       'Determined_W6', 'Professional_W6', 'Studious_W6', 'Imaginative_W6',\n",
    "       'Analytic_W7', 'Independent_W7', 'Determined_W7', 'Professional_W7',\n",
    "       'Studious_W7', 'Imaginative_W7', 'Analytic_W8', 'Independent_W8',\n",
    "       'Determined_W8', 'Professional_W8', 'Studious_W8', 'Imaginative_W8',\n",
    "       'Analytic_W9', 'Independent_W9', 'Determined_W9', 'Professional_W9',\n",
    "       'Studious_W9', 'Imaginative_W9', 'Analytic_W10', 'Independent_W10',\n",
    "       'Determined_W10', 'Professional_W10', 'Studious_W10', 'Imaginative_W10']].astype(int, errors='ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Talent CSV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>email</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "      <th>postcode</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>uni</th>\n",
       "      <th>degree</th>\n",
       "      <th>invited_date</th>\n",
       "      <th>month</th>\n",
       "      <th>invited_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>16</td>\n",
       "      <td>SHURLOCKE CRINGLE</td>\n",
       "      <td>Male</td>\n",
       "      <td>27/11/1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pentre</td>\n",
       "      <td>92427 Thierer Road</td>\n",
       "      <td>SY4</td>\n",
       "      <td>+44 947 829 3817</td>\n",
       "      <td>University of Leicester</td>\n",
       "      <td>2:2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>Rupert Ripple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>10</td>\n",
       "      <td>NICOLETTE BONEHILL</td>\n",
       "      <td>Female</td>\n",
       "      <td>14/08/1999</td>\n",
       "      <td>neebee9@addthis.com</td>\n",
       "      <td>East End</td>\n",
       "      <td>589 Columbus Way</td>\n",
       "      <td>BH21</td>\n",
       "      <td>+44-364-359-2606</td>\n",
       "      <td>Cranfield University</td>\n",
       "      <td>2:1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NOVEMBER 2019</td>\n",
       "      <td>Rupert Ripple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                name  gender         dob                email   \n",
       "3136  16   SHURLOCKE CRINGLE    Male  27/11/1995                  NaN  \\\n",
       "3521  10  NICOLETTE BONEHILL  Female  14/08/1999  neebee9@addthis.com   \n",
       "\n",
       "          city             address postcode      phone_number   \n",
       "3136    Pentre  92427 Thierer Road      SY4  +44 947 829 3817  \\\n",
       "3521  East End    589 Columbus Way     BH21  +44-364-359-2606   \n",
       "\n",
       "                          uni degree  invited_date          month   \n",
       "3136  University of Leicester    2:2          21.0       May 2019  \\\n",
       "3521     Cranfield University    2:1          19.0  NOVEMBER 2019   \n",
       "\n",
       "         invited_by  \n",
       "3136  Rupert Ripple  \n",
       "3521  Rupert Ripple  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicated names\n",
    "talent_csvs_df[talent_csvs_df['name'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>email</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "      <th>postcode</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>uni</th>\n",
       "      <th>degree</th>\n",
       "      <th>invited_date</th>\n",
       "      <th>month</th>\n",
       "      <th>invited_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, name, gender, dob, email, city, address, postcode, phone_number, uni, degree, invited_date, month, invited_by]\n",
       "Index: []"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_csvs_df[talent_csvs_df['name'] == 'Shurlocke Cringle']\n",
    "\n",
    "# These two appear to have the same name but be two different people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>email</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "      <th>postcode</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>uni</th>\n",
       "      <th>degree</th>\n",
       "      <th>invited_date</th>\n",
       "      <th>month</th>\n",
       "      <th>invited_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, name, gender, dob, email, city, address, postcode, phone_number, uni, degree, invited_date, month, invited_by]\n",
       "Index: []"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_csvs_df[talent_csvs_df['name'] == 'Nicolette Bonehill']\n",
    "\n",
    "# These two appear to have the same name but be two different people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting name column to upper case for consistency\n",
    "talent_csvs_df['name'] = talent_csvs_df['name'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>email</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "      <th>postcode</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>uni</th>\n",
       "      <th>degree</th>\n",
       "      <th>invited_date</th>\n",
       "      <th>month</th>\n",
       "      <th>invited_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, name, gender, dob, email, city, address, postcode, phone_number, uni, degree, invited_date, month, invited_by]\n",
       "Index: []"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Ely Kely in the dataframe (because a trainer Elly Kelly seemed to be misspelt as Ely Kely in the academy csvs)\n",
    "talent_csvs_df[talent_csvs_df['name'] == 'ELY KELY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the id column as it is not unique\n",
    "talent_csvs_df = talent_csvs_df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male', nan], dtype=object)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many categories for Gender\n",
    "talent_csvs_df['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Female to F and Male to M\n",
    "talent_csvs_df['gender'] = talent_csvs_df['gender'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting dob to datetime\n",
    "talent_csvs_df['dob'] = pd.to_datetime(talent_csvs_df['dob'], format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for invalid emails\n",
    "\n",
    "import re\n",
    "\n",
    "email_pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "\n",
    "def is_valid_email(email):\n",
    "    if re.match(email_pattern, email):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "emails = list(talent_csvs_df['email'])\n",
    "emails = [x for x in emails if not isinstance(x, float)]\n",
    "\n",
    "invalid_emails = []\n",
    "\n",
    "for email in emails:\n",
    "    if is_valid_email(email) == False:\n",
    "        invalid_emails.append(email)\n",
    "\n",
    "invalid_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping whitespace from either side of email values\n",
    "talent_csvs_df['email'] = talent_csvs_df['email'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping whitespace from either side of city values\n",
    "talent_csvs_df['city'] = talent_csvs_df['city'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Church End', 'West End', 'East End'], dtype=object)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any city values with whitespace in it\n",
    "talent_csvs_df[talent_csvs_df['city'].str.contains(r'\\s', na=False, regex=True)]['city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing leading zero from address values for consistency\n",
    "talent_csvs_df['address'] = talent_csvs_df['address'].str.strip().str.lstrip('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>email</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "      <th>postcode</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>uni</th>\n",
       "      <th>degree</th>\n",
       "      <th>invited_date</th>\n",
       "      <th>month</th>\n",
       "      <th>invited_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, gender, dob, email, city, address, postcode, phone_number, uni, degree, invited_date, month, invited_by]\n",
       "Index: []"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing whitespace from either side of postcode values\n",
    "talent_csvs_df['postcode'] = talent_csvs_df['postcode'].str.strip()\n",
    "\n",
    "# Checking for any postcode with whitespace in it\n",
    "talent_csvs_df[talent_csvs_df['postcode'].str.contains(r'\\s', na=False, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SN1', 'OX12', 'GU32', 'CT15', 'WF9', 'B12', 'BD23', 'CB4', 'DN36',\n",
       "       'BS14', 'KW10', 'G4', nan, 'WC1B', 'BT66', 'B40', 'LE15', 'L33',\n",
       "       'LE14', 'CT16', 'CV35', 'SW19', 'WC2H', 'BS41', 'NR29', 'EH52',\n",
       "       'SG4', 'OX7', 'DN22', 'DL10', 'NR34', 'NN4', 'LS6', 'S8', 'EC3M',\n",
       "       'M14', 'DL8', 'BS37', 'GL54', 'BD7', 'LE16', 'TF6', 'IV1', 'LS9',\n",
       "       'BT2', 'CH48', 'N3', 'AB55', 'AB56', 'NG22', 'AB39', 'DN21', 'SY4',\n",
       "       'DT10', 'L74', 'RG20', 'SN13', 'S1', 'EC1V', 'RH5', 'NN11', 'S33',\n",
       "       'NE46', 'ST20', 'PH43', 'PR1', 'W1F', 'M34', 'EH9', 'NG34', 'SW1E',\n",
       "       'BH21', 'LN6'], dtype=object)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_csvs_df['postcode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "no_of_rows_in_talent_csvs_df = len(talent_csvs_df)\n",
    "no_of_null_values_for_phone_num = len(talent_csvs_df[talent_csvs_df['phone_number'].isnull()])\n",
    "no_of_phone_num_starting_with_plus_44 = len(talent_csvs_df[talent_csvs_df['phone_number'].str.contains(r'^\\+44', na=False, regex=True)])\n",
    "\n",
    "# Checking if all phone_numbers are null or start with +44\n",
    "print((no_of_phone_num_starting_with_plus_44 + no_of_null_values_for_phone_num) / no_of_rows_in_talent_csvs_df)\n",
    "\n",
    "# This is the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'+', '6', '7', ' ', '2', '3', '5', '8', '0', '4', '(', '-', ')', '9', '1'}\n"
     ]
    }
   ],
   "source": [
    "# Print all characters in column phone_number\n",
    "unique_chars = set()\n",
    "\n",
    "values = talent_csvs_df['phone_number'].str.cat()\n",
    "unique_chars.update(set(values))\n",
    "\n",
    "print(unique_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace everything except 0-9 and + with nothing leaving number in format +44##########\n",
    "unwanted_chars = ['-', ' ', ')', '(']\n",
    "pattern = '[' + re.escape(''.join(unwanted_chars)) + ']'\n",
    "\n",
    "talent_csvs_df['phone_number'] = talent_csvs_df['phone_number'].str.replace(pattern, '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing white space either side of value in cells of uni\n",
    "talent_csvs_df['uni'] = talent_csvs_df['uni'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2:1', '1st', '3rd', nan, '2:2'], dtype=object)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if degree classifications are correct and as expected in the three categories 1st, 2:1, 2:2 and 3rd\n",
    "talent_csvs_df['degree'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since invited date columns are misnamed, we will rename the columns\n",
    "talent_csvs_df = talent_csvs_df.rename(columns={'invited_date': 'invited_date_day', 'month': 'invited_date_month_and_year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting invited_day_date to integers\n",
    "talent_csvs_df['invited_date_day'] = talent_csvs_df['invited_date_day'].astype(int, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['April 2019', nan, 'AUGUST 2019', 'DECEMBER 2019', 'February 2019',\n",
       "       'January 2019', 'JULY 2019', 'JUNE 2019', 'March 2019', 'May 2019',\n",
       "       'NOVEMBER 2019', 'OCTOBER 2019', 'SEPT 2019'], dtype=object)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_csvs_df['invited_date_month_and_year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the values for consistency\n",
    "update_dict = {\n",
    "    'April 2019': '2019-04',\n",
    "    'AUGUST 2019': '2019-08', \n",
    "    'DECEMBER 2019': '2019-12', \n",
    "    'February 2019': '2019-02',\n",
    "    'January 2019': '2019-01', \n",
    "    'JULY 2019': '2019-07', \n",
    "    'JUNE 2019': '2019-06', \n",
    "    'March 2019': '2019-03', \n",
    "    'May 2019': '2019-05',\n",
    "    'NOVEMBER 2019': '2019-11', \n",
    "    'OCTOBER 2019': '2019-10', \n",
    "    'SEPT 2019': '2019-09'\n",
    "}\n",
    "\n",
    "talent_csvs_df['invited_date_month_and_year'] = talent_csvs_df['invited_date_month_and_year'].replace(update_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bruno Bellbrook', 'Doris Bellasis', 'Gismo Tilling', nan,\n",
       "       'Stacey Broad', 'Fifi Eton', 'Sunny Sladefield', 'Rupert Ripple',\n",
       "       'Fifi Etton', 'Bruno Belbrook'], dtype=object)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking what invitors are in dataset\n",
    "talent_csvs_df['invited_by'].unique()\n",
    "\n",
    "# It seems Bruno Bellbrook is mispelt as Bruno Belbrook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating correcting misspelt Bruno Belbrook to Bruno Bellbrook\n",
    "talent_csvs_df['invited_by'] = talent_csvs_df['invited_by'].replace({'Bruno Belbrook': 'Bruno Bellbrook'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>email</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "      <th>postcode</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>uni</th>\n",
       "      <th>degree</th>\n",
       "      <th>invited_date_day</th>\n",
       "      <th>invited_date_month_and_year</th>\n",
       "      <th>invited_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESME TRUSSLOVE</td>\n",
       "      <td>F</td>\n",
       "      <td>1994-04-08</td>\n",
       "      <td>etrusslove0@google.es</td>\n",
       "      <td>Swindon</td>\n",
       "      <td>22056 Lerdahl Avenue</td>\n",
       "      <td>SN1</td>\n",
       "      <td>+442957830228</td>\n",
       "      <td>Saint George's Hospital Medical School, Univer...</td>\n",
       "      <td>2:1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>Bruno Bellbrook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MATTHAEUS AUDAS</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>maudas1@mapquest.com</td>\n",
       "      <td>Charlton</td>\n",
       "      <td>263 Nelson Trail</td>\n",
       "      <td>OX12</td>\n",
       "      <td>+449577280155</td>\n",
       "      <td>Keele University</td>\n",
       "      <td>2:1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>Doris Bellasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEREY TOLLFREE</td>\n",
       "      <td>F</td>\n",
       "      <td>1992-08-12</td>\n",
       "      <td>ctollfree2@netvibes.com</td>\n",
       "      <td>Weston</td>\n",
       "      <td>69 Coleman Court</td>\n",
       "      <td>GU32</td>\n",
       "      <td>+445887496002</td>\n",
       "      <td>King's College London, University of London</td>\n",
       "      <td>2:1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>Gismo Tilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ERYN SPEERS</td>\n",
       "      <td>F</td>\n",
       "      <td>NaT</td>\n",
       "      <td>espeers3@shinystat.com</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>166 Daystar Drive</td>\n",
       "      <td>CT15</td>\n",
       "      <td>+441487870613</td>\n",
       "      <td>University of Edinburgh</td>\n",
       "      <td>2:1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THEADORA BERKELAY</td>\n",
       "      <td>F</td>\n",
       "      <td>1995-03-11</td>\n",
       "      <td>tberkelay4@godaddy.com</td>\n",
       "      <td>Upton</td>\n",
       "      <td>6 Mandrake Crossing</td>\n",
       "      <td>WF9</td>\n",
       "      <td>+448414683619</td>\n",
       "      <td>University of Leicester</td>\n",
       "      <td>2:1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>Stacey Broad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>CLYVE GILLHESPY</td>\n",
       "      <td>M</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>cgillhespybj@buzzfeed.com</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>33 Almo Avenue</td>\n",
       "      <td>B40</td>\n",
       "      <td>+449043432218</td>\n",
       "      <td>University of Liverpool</td>\n",
       "      <td>2:1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>Bruno Bellbrook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4687</th>\n",
       "      <td>VACLAV PIETESCH</td>\n",
       "      <td>M</td>\n",
       "      <td>1994-09-11</td>\n",
       "      <td>vpieteschbk@mac.com</td>\n",
       "      <td>Whitwell</td>\n",
       "      <td>6476 Hoffman Terrace</td>\n",
       "      <td>DL10</td>\n",
       "      <td>+444556316125</td>\n",
       "      <td>Sheffield Hallam University</td>\n",
       "      <td>2:2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>Stacey Broad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4688</th>\n",
       "      <td>KASSI LUCIO</td>\n",
       "      <td>F</td>\n",
       "      <td>1994-04-24</td>\n",
       "      <td>kluciobl@exblog.jp</td>\n",
       "      <td>Normanton</td>\n",
       "      <td>6 Fulton Center</td>\n",
       "      <td>LE15</td>\n",
       "      <td>+448343429323</td>\n",
       "      <td>University of Buckingham</td>\n",
       "      <td>2:1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>Fifi Eton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4689</th>\n",
       "      <td>VIVIANNA LETTY</td>\n",
       "      <td>F</td>\n",
       "      <td>NaT</td>\n",
       "      <td>vlettybm@google.com.hk</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>78314 Fisk Plaza</td>\n",
       "      <td>S1</td>\n",
       "      <td>+445347583140</td>\n",
       "      <td>Leeds Metropolitan University</td>\n",
       "      <td>1st</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>Bruno Bellbrook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4690</th>\n",
       "      <td>MERCIE GROGER</td>\n",
       "      <td>F</td>\n",
       "      <td>1997-10-05</td>\n",
       "      <td>mgrogerbn@timesonline.co.uk</td>\n",
       "      <td>Charlton</td>\n",
       "      <td>5 Toban Circle</td>\n",
       "      <td>OX12</td>\n",
       "      <td>+446622394688</td>\n",
       "      <td>ifs University College</td>\n",
       "      <td>3rd</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>Rupert Ripple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4691 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name gender        dob                        email   \n",
       "0        ESME TRUSSLOVE      F 1994-04-08        etrusslove0@google.es  \\\n",
       "1       MATTHAEUS AUDAS      M        NaT         maudas1@mapquest.com   \n",
       "2       CHEREY TOLLFREE      F 1992-08-12      ctollfree2@netvibes.com   \n",
       "3           ERYN SPEERS      F        NaT       espeers3@shinystat.com   \n",
       "4     THEADORA BERKELAY      F 1995-03-11       tberkelay4@godaddy.com   \n",
       "...                 ...    ...        ...                          ...   \n",
       "4686    CLYVE GILLHESPY      M 1995-12-15    cgillhespybj@buzzfeed.com   \n",
       "4687    VACLAV PIETESCH      M 1994-09-11          vpieteschbk@mac.com   \n",
       "4688        KASSI LUCIO      F 1994-04-24           kluciobl@exblog.jp   \n",
       "4689     VIVIANNA LETTY      F        NaT       vlettybm@google.com.hk   \n",
       "4690      MERCIE GROGER      F 1997-10-05  mgrogerbn@timesonline.co.uk   \n",
       "\n",
       "            city               address postcode   phone_number   \n",
       "0        Swindon  22056 Lerdahl Avenue      SN1  +442957830228  \\\n",
       "1       Charlton      263 Nelson Trail     OX12  +449577280155   \n",
       "2         Weston      69 Coleman Court     GU32  +445887496002   \n",
       "3         Sutton     166 Daystar Drive     CT15  +441487870613   \n",
       "4          Upton   6 Mandrake Crossing      WF9  +448414683619   \n",
       "...          ...                   ...      ...            ...   \n",
       "4686  Birmingham        33 Almo Avenue      B40  +449043432218   \n",
       "4687    Whitwell  6476 Hoffman Terrace     DL10  +444556316125   \n",
       "4688   Normanton       6 Fulton Center     LE15  +448343429323   \n",
       "4689   Sheffield      78314 Fisk Plaza       S1  +445347583140   \n",
       "4690    Charlton        5 Toban Circle     OX12  +446622394688   \n",
       "\n",
       "                                                    uni degree   \n",
       "0     Saint George's Hospital Medical School, Univer...    2:1  \\\n",
       "1                                      Keele University    2:1   \n",
       "2           King's College London, University of London    2:1   \n",
       "3                               University of Edinburgh    2:1   \n",
       "4                               University of Leicester    2:1   \n",
       "...                                                 ...    ...   \n",
       "4686                            University of Liverpool    2:1   \n",
       "4687                        Sheffield Hallam University    2:2   \n",
       "4688                           University of Buckingham    2:1   \n",
       "4689                      Leeds Metropolitan University    1st   \n",
       "4690                             ifs University College    3rd   \n",
       "\n",
       "      invited_date_day invited_date_month_and_year       invited_by  \n",
       "0                 10.0                     2019-04  Bruno Bellbrook  \n",
       "1                 30.0                     2019-04   Doris Bellasis  \n",
       "2                 25.0                     2019-04    Gismo Tilling  \n",
       "3                  NaN                         NaN              NaN  \n",
       "4                  2.0                     2019-04     Stacey Broad  \n",
       "...                ...                         ...              ...  \n",
       "4686              26.0                     2019-09  Bruno Bellbrook  \n",
       "4687              12.0                     2019-09     Stacey Broad  \n",
       "4688               3.0                     2019-09        Fifi Eton  \n",
       "4689              19.0                     2019-09  Bruno Bellbrook  \n",
       "4690              12.0                     2019-09    Rupert Ripple  \n",
       "\n",
       "[4691 rows x 13 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_csvs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                   object\n",
       "gender                                 object\n",
       "dob                            datetime64[ns]\n",
       "email                                  object\n",
       "city                                   object\n",
       "address                                object\n",
       "postcode                               object\n",
       "phone_number                           object\n",
       "uni                                    object\n",
       "degree                                 object\n",
       "invited_date_day                      float64\n",
       "invited_date_month_and_year            object\n",
       "invited_by                             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_csvs_df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Clean Talent CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_talent_csvs_df(df):\n",
    "\n",
    "    # Converting name column to upper case for consistency\n",
    "    df['name'] = df['name'].str.strip().str.upper()\n",
    "\n",
    "    # Dropping the id column as it is not unique\n",
    "    df = df.drop('id', axis=1)\n",
    "\n",
    "    # Changing Female to F and Male to M\n",
    "    df['gender'] = df['gender'].str[0]\n",
    "    \n",
    "    # Casting dob to datetime\n",
    "    df['dob'] = pd.to_datetime(df['dob'], format='mixed')\n",
    "\n",
    "    # Stripping whitespace from either side of email values\n",
    "    df['email'] = df['email'].str.strip()\n",
    "\n",
    "    # Stripping whitespace from either side of city values\n",
    "    df['city'] = df['city'].str.strip()\n",
    "\n",
    "    # Removing leading zero from address values for consistency\n",
    "    df['address'] = df['address'].str.strip().str.lstrip('0')\n",
    "\n",
    "    # Removing whitespace from either side of postcode values\n",
    "    df['postcode'] = df['postcode'].str.strip()\n",
    "\n",
    "    # Replacing everything except 0-9 and + with nothing leaving number in format +44##########\n",
    "    unwanted_chars = ['-', ' ', ')', '(']\n",
    "    pattern = '[' + re.escape(''.join(unwanted_chars)) + ']'\n",
    "    df['phone_number'] = df['phone_number'].str.replace(pattern, '', regex=True)\n",
    "\n",
    "    # Removing white space either side of value in cells of uni\n",
    "    df['uni'] = df['uni'].str.strip()\n",
    "\n",
    "    # Since invited date columns are misnamed, we will rename the columns\n",
    "    df = df.rename(columns={'invited_date': 'invited_date_day', 'month': 'invited_date_month_and_year'})\n",
    "\n",
    "    # Casting invited_day_date to integers\n",
    "    df['invited_date_day'] = df['invited_date_day'].astype(int, errors='ignore')\n",
    "\n",
    "    # Updating the values for consistency\n",
    "    update_dict = {\n",
    "        'April 2019': '2019-04',\n",
    "        'AUGUST 2019': '2019-08', \n",
    "        'DECEMBER 2019': '2019-12', \n",
    "        'February 2019': '2019-02',\n",
    "        'January 2019': '2019-01', \n",
    "        'JULY 2019': '2019-07', \n",
    "        'JUNE 2019': '2019-06', \n",
    "        'March 2019': '2019-03', \n",
    "        'May 2019': '2019-05',\n",
    "        'NOVEMBER 2019': '2019-11', \n",
    "        'OCTOBER 2019': '2019-10', \n",
    "        'SEPT 2019': '2019-09'\n",
    "    }\n",
    "    df['invited_date_month_and_year'] = df['invited_date_month_and_year'].replace(update_dict)\n",
    "\n",
    "    # Updating correcting misspelt Bruno Belbrook to Bruno Bellbrook\n",
    "    df['invited_by'] = df['invited_by'].replace({'Bruno Belbrook': 'Bruno Bellbrook'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Talent JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>strengths</th>\n",
       "      <th>weaknesses</th>\n",
       "      <th>self_development</th>\n",
       "      <th>geo_flex</th>\n",
       "      <th>financial_support_self</th>\n",
       "      <th>result</th>\n",
       "      <th>course_interest</th>\n",
       "      <th>tech_self_score.C#</th>\n",
       "      <th>tech_self_score.Java</th>\n",
       "      <th>tech_self_score.R</th>\n",
       "      <th>tech_self_score.JavaScript</th>\n",
       "      <th>tech_self_score.Python</th>\n",
       "      <th>tech_self_score.C++</th>\n",
       "      <th>tech_self_score.Ruby</th>\n",
       "      <th>tech_self_score.SPSS</th>\n",
       "      <th>tech_self_score.PHP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stillmann Castano</td>\n",
       "      <td>22/08/2019</td>\n",
       "      <td>['Charisma']</td>\n",
       "      <td>['Distracted', 'Impulsive', 'Introverted']</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Business</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hilary Willmore</td>\n",
       "      <td>01/08/2019</td>\n",
       "      <td>['Patient', 'Curious', 'Problem Solving']</td>\n",
       "      <td>['Overbearing', 'Chatty', 'Indifferent']</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fail</td>\n",
       "      <td>Data</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Efrem Whipple</td>\n",
       "      <td>22/08/2019</td>\n",
       "      <td>['Courteous', 'Independent', 'Patient']</td>\n",
       "      <td>['Introverted', 'Impulsive', 'Anxious']</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sydel Fenne</td>\n",
       "      <td>28/08/2019</td>\n",
       "      <td>['Passionate']</td>\n",
       "      <td>['Perfectionist', 'Sensitive']</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michel Lebarree</td>\n",
       "      <td>07/08/2019</td>\n",
       "      <td>['Versatile']</td>\n",
       "      <td>['Controlling', 'Perfectionist', 'Chatty']</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>Jacky Reilingen</td>\n",
       "      <td>04/04/2019</td>\n",
       "      <td>['Versatile']</td>\n",
       "      <td>['Indifferent', 'Intolerant', 'Introverted']</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fail</td>\n",
       "      <td>Business</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>Phillis Lyfield</td>\n",
       "      <td>10/04/2019</td>\n",
       "      <td>['Organisation', 'Independent', 'Determined']</td>\n",
       "      <td>['Sensitive', 'Overbearing', 'Impatient']</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>Celle Barlas</td>\n",
       "      <td>16/04/2019</td>\n",
       "      <td>['Problem Solving']</td>\n",
       "      <td>['Critical']</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>Scott Duny</td>\n",
       "      <td>11/04/2019</td>\n",
       "      <td>['Reliable', 'Perfectionism', 'Problem Solving']</td>\n",
       "      <td>['Stubborn']</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>Boycey Matushenko</td>\n",
       "      <td>25/04/2019</td>\n",
       "      <td>['Independent']</td>\n",
       "      <td>['Controlling', 'Stubborn']</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fail</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3105 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name        date   \n",
       "0     Stillmann Castano  22/08/2019  \\\n",
       "1       Hilary Willmore  01/08/2019   \n",
       "2         Efrem Whipple  22/08/2019   \n",
       "3           Sydel Fenne  28/08/2019   \n",
       "4       Michel Lebarree  07/08/2019   \n",
       "...                 ...         ...   \n",
       "3100    Jacky Reilingen  04/04/2019   \n",
       "3101    Phillis Lyfield  10/04/2019   \n",
       "3102       Celle Barlas  16/04/2019   \n",
       "3103         Scott Duny  11/04/2019   \n",
       "3104  Boycey Matushenko  25/04/2019   \n",
       "\n",
       "                                             strengths   \n",
       "0                                         ['Charisma']  \\\n",
       "1            ['Patient', 'Curious', 'Problem Solving']   \n",
       "2              ['Courteous', 'Independent', 'Patient']   \n",
       "3                                       ['Passionate']   \n",
       "4                                        ['Versatile']   \n",
       "...                                                ...   \n",
       "3100                                     ['Versatile']   \n",
       "3101     ['Organisation', 'Independent', 'Determined']   \n",
       "3102                               ['Problem Solving']   \n",
       "3103  ['Reliable', 'Perfectionism', 'Problem Solving']   \n",
       "3104                                   ['Independent']   \n",
       "\n",
       "                                        weaknesses self_development geo_flex   \n",
       "0       ['Distracted', 'Impulsive', 'Introverted']              Yes      Yes  \\\n",
       "1         ['Overbearing', 'Chatty', 'Indifferent']               No      Yes   \n",
       "2          ['Introverted', 'Impulsive', 'Anxious']              Yes      Yes   \n",
       "3                   ['Perfectionist', 'Sensitive']              Yes      Yes   \n",
       "4       ['Controlling', 'Perfectionist', 'Chatty']              Yes      Yes   \n",
       "...                                            ...              ...      ...   \n",
       "3100  ['Indifferent', 'Intolerant', 'Introverted']              Yes       No   \n",
       "3101     ['Sensitive', 'Overbearing', 'Impatient']              Yes      Yes   \n",
       "3102                                  ['Critical']              Yes      Yes   \n",
       "3103                                  ['Stubborn']              Yes      Yes   \n",
       "3104                   ['Controlling', 'Stubborn']              Yes      Yes   \n",
       "\n",
       "     financial_support_self result course_interest  tech_self_score.C#   \n",
       "0                       Yes   Pass        Business                 6.0  \\\n",
       "1                       Yes   Fail            Data                 4.0   \n",
       "2                       Yes   Pass        Business                 NaN   \n",
       "3                       Yes   Pass            Data                 NaN   \n",
       "4                       Yes   Pass     Engineering                 NaN   \n",
       "...                     ...    ...             ...                 ...   \n",
       "3100                    Yes   Fail        Business                 2.0   \n",
       "3101                    Yes   Pass     Engineering                 4.0   \n",
       "3102                    Yes   Pass     Engineering                 NaN   \n",
       "3103                    Yes   Pass            Data                 NaN   \n",
       "3104                     No   Fail     Engineering                 3.0   \n",
       "\n",
       "      tech_self_score.Java  tech_self_score.R  tech_self_score.JavaScript   \n",
       "0                      5.0                2.0                         2.0  \\\n",
       "1                      2.0                NaN                         NaN   \n",
       "2                      NaN                NaN                         NaN   \n",
       "3                      3.0                NaN                         NaN   \n",
       "4                      4.0                2.0                         NaN   \n",
       "...                    ...                ...                         ...   \n",
       "3100                   6.0                1.0                         NaN   \n",
       "3101                   4.0                NaN                         NaN   \n",
       "3102                   NaN                2.0                         4.0   \n",
       "3103                   NaN                NaN                         NaN   \n",
       "3104                   3.0                NaN                         NaN   \n",
       "\n",
       "      tech_self_score.Python  tech_self_score.C++  tech_self_score.Ruby   \n",
       "0                        NaN                  NaN                   NaN  \\\n",
       "1                        1.0                  4.0                   NaN   \n",
       "2                        NaN                  4.0                   4.0   \n",
       "3                        NaN                  NaN                   NaN   \n",
       "4                        3.0                  3.0                   1.0   \n",
       "...                      ...                  ...                   ...   \n",
       "3100                     NaN                  NaN                   NaN   \n",
       "3101                     NaN                  NaN                   4.0   \n",
       "3102                     NaN                  1.0                   NaN   \n",
       "3103                     NaN                  NaN                   3.0   \n",
       "3104                     2.0                  4.0                   NaN   \n",
       "\n",
       "      tech_self_score.SPSS  tech_self_score.PHP  \n",
       "0                      NaN                  NaN  \n",
       "1                      NaN                  NaN  \n",
       "2                      NaN                  NaN  \n",
       "3                      4.0                  NaN  \n",
       "4                      NaN                  2.0  \n",
       "...                    ...                  ...  \n",
       "3100                   4.0                  NaN  \n",
       "3101                   NaN                  1.0  \n",
       "3102                   NaN                  NaN  \n",
       "3103                   NaN                  NaN  \n",
       "3104                   NaN                  NaN  \n",
       "\n",
       "[3105 rows x 18 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_jsons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'date', 'strengths', 'weaknesses', 'self_development',\n",
       "       'geo_flex', 'financial_support_self', 'result', 'course_interest',\n",
       "       'tech_self_score.C#', 'tech_self_score.Java', 'tech_self_score.R',\n",
       "       'tech_self_score.JavaScript', 'tech_self_score.Python',\n",
       "       'tech_self_score.C++', 'tech_self_score.Ruby', 'tech_self_score.SPSS',\n",
       "       'tech_self_score.PHP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_jsons_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting name to upper case for consistency\n",
    "\n",
    "talent_jsons_df['name'] = talent_jsons_df['name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list columns strengths and weaknesses to strings\n",
    "talent_jsons_df['strengths'] = talent_jsons_df['strengths'].apply(lambda x: str(x))\n",
    "talent_jsons_df['weaknesses'] = talent_jsons_df['weaknesses'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicate rows\n",
    "talent_jsons_df = talent_jsons_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking what values are in the 'self_development' column\n",
    "talent_jsons_df['self_development'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Yes/No with True/False in 'self_development'\n",
    "talent_jsons_df.loc[:, 'self_development'] = talent_jsons_df['self_development'].map({'Yes': True, 'No': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking what values are in the 'geo_flex' column\n",
    "talent_jsons_df['geo_flex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Yes/No with True/False in 'geo_flex'\n",
    "talent_jsons_df.loc[:, 'geo_flex'] = talent_jsons_df['geo_flex'].map({'Yes': True, 'No': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking what values are in the 'financial_support_self' column\n",
    "talent_jsons_df['financial_support_self'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Yes/No with True/False in 'financial_support_self'\n",
    "talent_jsons_df.loc[:, 'financial_support_self'] = talent_jsons_df['financial_support_self'].map({'Yes': True, 'No': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pass', 'Fail'], dtype=object)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking what values are in the 'result' column\n",
    "talent_jsons_df['result'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Business', 'Data', 'Engineering'], dtype=object)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking what course_interest values exist\n",
    "talent_jsons_df['course_interest'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  4., nan,  3.,  2.,  7.,  1.,  8.,  5.,  9., 12., 10., 11.])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking what unique values we have in the self_score columns\n",
    "self_score_cols = ['tech_self_score.C#',\n",
    "                   'tech_self_score.Java',\n",
    "                   'tech_self_score.R',\n",
    "                   'tech_self_score.JavaScript',\n",
    "                   'tech_self_score.Python',\n",
    "                   'tech_self_score.C++',\n",
    "                   'tech_self_score.Ruby',\n",
    "                   'tech_self_score.SPSS', 'tech_self_score.PHP']\n",
    "unique_self_score_values = []\n",
    "for col in self_score_cols:\n",
    "    unique_values_in_col = talent_jsons_df[col].unique()\n",
    "    unique_self_score_values.extend(unique_values_in_col)\n",
    "\n",
    "unique_self_score_values = pd.Series(unique_self_score_values).unique()\n",
    "\n",
    "unique_self_score_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3324\\2855115863.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  talent_jsons_df[col] = talent_jsons_df[col].map(float_to_int_dict).astype('Int64')\n"
     ]
    }
   ],
   "source": [
    "# Casting all floats in self_score columns to integers\n",
    "\n",
    "columns_to_convert = ['tech_self_score.C#',\n",
    "                      'tech_self_score.Java',\n",
    "                      'tech_self_score.R',\n",
    "                      'tech_self_score.JavaScript',\n",
    "                      'tech_self_score.Python',\n",
    "                      'tech_self_score.C++',\n",
    "                      'tech_self_score.Ruby',\n",
    "                      'tech_self_score.SPSS',\n",
    "                      'tech_self_score.PHP']\n",
    "\n",
    "float_to_int_dict = {\n",
    "    1.0: 1,\n",
    "    2.0: 2,\n",
    "    3.0: 3,\n",
    "    4.0: 4,\n",
    "    5.0: 5,\n",
    "    6.0: 6,\n",
    "    7.0: 7,\n",
    "    8.0: 8,\n",
    "    9.0: 9,\n",
    "    10.0: 10,\n",
    "    11.0: 11,\n",
    "    12.0: 12\n",
    "}\n",
    "\n",
    "# Use the map() method with the float_to_int_dict to convert floats to integers\n",
    "for col in columns_to_convert:\n",
    "    talent_jsons_df[col] = talent_jsons_df[col].map(float_to_int_dict).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>strengths</th>\n",
       "      <th>weaknesses</th>\n",
       "      <th>self_development</th>\n",
       "      <th>geo_flex</th>\n",
       "      <th>financial_support_self</th>\n",
       "      <th>result</th>\n",
       "      <th>course_interest</th>\n",
       "      <th>tech_self_score.C#</th>\n",
       "      <th>tech_self_score.Java</th>\n",
       "      <th>tech_self_score.R</th>\n",
       "      <th>tech_self_score.JavaScript</th>\n",
       "      <th>tech_self_score.Python</th>\n",
       "      <th>tech_self_score.C++</th>\n",
       "      <th>tech_self_score.Ruby</th>\n",
       "      <th>tech_self_score.SPSS</th>\n",
       "      <th>tech_self_score.PHP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stillmann Castano</td>\n",
       "      <td>22/08/2019</td>\n",
       "      <td>['Charisma']</td>\n",
       "      <td>['Distracted', 'Impulsive', 'Introverted']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Business</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hilary Willmore</td>\n",
       "      <td>01/08/2019</td>\n",
       "      <td>['Patient', 'Curious', 'Problem Solving']</td>\n",
       "      <td>['Overbearing', 'Chatty', 'Indifferent']</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Fail</td>\n",
       "      <td>Data</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Efrem Whipple</td>\n",
       "      <td>22/08/2019</td>\n",
       "      <td>['Courteous', 'Independent', 'Patient']</td>\n",
       "      <td>['Introverted', 'Impulsive', 'Anxious']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Business</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sydel Fenne</td>\n",
       "      <td>28/08/2019</td>\n",
       "      <td>['Passionate']</td>\n",
       "      <td>['Perfectionist', 'Sensitive']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Data</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michel Lebarree</td>\n",
       "      <td>07/08/2019</td>\n",
       "      <td>['Versatile']</td>\n",
       "      <td>['Controlling', 'Perfectionist', 'Chatty']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>Jacky Reilingen</td>\n",
       "      <td>04/04/2019</td>\n",
       "      <td>['Versatile']</td>\n",
       "      <td>['Indifferent', 'Intolerant', 'Introverted']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Fail</td>\n",
       "      <td>Business</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>Phillis Lyfield</td>\n",
       "      <td>10/04/2019</td>\n",
       "      <td>['Organisation', 'Independent', 'Determined']</td>\n",
       "      <td>['Sensitive', 'Overbearing', 'Impatient']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>Celle Barlas</td>\n",
       "      <td>16/04/2019</td>\n",
       "      <td>['Problem Solving']</td>\n",
       "      <td>['Critical']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>Scott Duny</td>\n",
       "      <td>11/04/2019</td>\n",
       "      <td>['Reliable', 'Perfectionism', 'Problem Solving']</td>\n",
       "      <td>['Stubborn']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Data</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>Boycey Matushenko</td>\n",
       "      <td>25/04/2019</td>\n",
       "      <td>['Independent']</td>\n",
       "      <td>['Controlling', 'Stubborn']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Fail</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3073 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name        date   \n",
       "0     Stillmann Castano  22/08/2019  \\\n",
       "1       Hilary Willmore  01/08/2019   \n",
       "2         Efrem Whipple  22/08/2019   \n",
       "3           Sydel Fenne  28/08/2019   \n",
       "4       Michel Lebarree  07/08/2019   \n",
       "...                 ...         ...   \n",
       "3100    Jacky Reilingen  04/04/2019   \n",
       "3101    Phillis Lyfield  10/04/2019   \n",
       "3102       Celle Barlas  16/04/2019   \n",
       "3103         Scott Duny  11/04/2019   \n",
       "3104  Boycey Matushenko  25/04/2019   \n",
       "\n",
       "                                             strengths   \n",
       "0                                         ['Charisma']  \\\n",
       "1            ['Patient', 'Curious', 'Problem Solving']   \n",
       "2              ['Courteous', 'Independent', 'Patient']   \n",
       "3                                       ['Passionate']   \n",
       "4                                        ['Versatile']   \n",
       "...                                                ...   \n",
       "3100                                     ['Versatile']   \n",
       "3101     ['Organisation', 'Independent', 'Determined']   \n",
       "3102                               ['Problem Solving']   \n",
       "3103  ['Reliable', 'Perfectionism', 'Problem Solving']   \n",
       "3104                                   ['Independent']   \n",
       "\n",
       "                                        weaknesses self_development geo_flex   \n",
       "0       ['Distracted', 'Impulsive', 'Introverted']             True     True  \\\n",
       "1         ['Overbearing', 'Chatty', 'Indifferent']            False     True   \n",
       "2          ['Introverted', 'Impulsive', 'Anxious']             True     True   \n",
       "3                   ['Perfectionist', 'Sensitive']             True     True   \n",
       "4       ['Controlling', 'Perfectionist', 'Chatty']             True     True   \n",
       "...                                            ...              ...      ...   \n",
       "3100  ['Indifferent', 'Intolerant', 'Introverted']             True    False   \n",
       "3101     ['Sensitive', 'Overbearing', 'Impatient']             True     True   \n",
       "3102                                  ['Critical']             True     True   \n",
       "3103                                  ['Stubborn']             True     True   \n",
       "3104                   ['Controlling', 'Stubborn']             True     True   \n",
       "\n",
       "     financial_support_self result course_interest  tech_self_score.C#   \n",
       "0                      True   Pass        Business                   6  \\\n",
       "1                      True   Fail            Data                   4   \n",
       "2                      True   Pass        Business                <NA>   \n",
       "3                      True   Pass            Data                <NA>   \n",
       "4                      True   Pass     Engineering                <NA>   \n",
       "...                     ...    ...             ...                 ...   \n",
       "3100                   True   Fail        Business                   2   \n",
       "3101                   True   Pass     Engineering                   4   \n",
       "3102                   True   Pass     Engineering                <NA>   \n",
       "3103                   True   Pass            Data                <NA>   \n",
       "3104                  False   Fail     Engineering                   3   \n",
       "\n",
       "      tech_self_score.Java  tech_self_score.R  tech_self_score.JavaScript   \n",
       "0                        5                  2                           2  \\\n",
       "1                        2               <NA>                        <NA>   \n",
       "2                     <NA>               <NA>                        <NA>   \n",
       "3                        3               <NA>                        <NA>   \n",
       "4                        4                  2                        <NA>   \n",
       "...                    ...                ...                         ...   \n",
       "3100                     6                  1                        <NA>   \n",
       "3101                     4               <NA>                        <NA>   \n",
       "3102                  <NA>                  2                           4   \n",
       "3103                  <NA>               <NA>                        <NA>   \n",
       "3104                     3               <NA>                        <NA>   \n",
       "\n",
       "      tech_self_score.Python  tech_self_score.C++  tech_self_score.Ruby   \n",
       "0                       <NA>                 <NA>                  <NA>  \\\n",
       "1                          1                    4                  <NA>   \n",
       "2                       <NA>                    4                     4   \n",
       "3                       <NA>                 <NA>                  <NA>   \n",
       "4                          3                    3                     1   \n",
       "...                      ...                  ...                   ...   \n",
       "3100                    <NA>                 <NA>                  <NA>   \n",
       "3101                    <NA>                 <NA>                     4   \n",
       "3102                    <NA>                    1                  <NA>   \n",
       "3103                    <NA>                 <NA>                     3   \n",
       "3104                       2                    4                  <NA>   \n",
       "\n",
       "      tech_self_score.SPSS  tech_self_score.PHP  \n",
       "0                     <NA>                 <NA>  \n",
       "1                     <NA>                 <NA>  \n",
       "2                     <NA>                 <NA>  \n",
       "3                        4                 <NA>  \n",
       "4                     <NA>                    2  \n",
       "...                    ...                  ...  \n",
       "3100                     4                 <NA>  \n",
       "3101                  <NA>                    1  \n",
       "3102                  <NA>                 <NA>  \n",
       "3103                  <NA>                 <NA>  \n",
       "3104                  <NA>                 <NA>  \n",
       "\n",
       "[3073 rows x 18 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_jsons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Clean Talent JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_talent_jsons_df(df):\n",
    "\n",
    "    # Converting name to upper case for consistency\n",
    "    df['name'] = df['name'].str.upper()\n",
    "\n",
    "    # Convert list columns strengths and weaknesses to strings\n",
    "    df['strengths'] = df['strengths'].apply(lambda x: str(x))\n",
    "    df['weaknesses'] = df['weaknesses'].apply(lambda x: str(x))\n",
    "\n",
    "    # Dropping duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Replacing Yes/No with True/False in 'self_development'\n",
    "    df.loc[:, 'self_development'] = df['self_development'].map({'Yes': True, 'No': False})\n",
    "\n",
    "    # Replacing Yes/No with True/False in 'geo_flex'\n",
    "    df.loc[:, 'geo_flex'] = df['geo_flex'].map({'Yes': True, 'No': False})\n",
    "\n",
    "    # Replacing Yes/No with True/False in 'financial_support_self'\n",
    "    df.loc[:, 'financial_support_self'] = df['financial_support_self'].map({'Yes': True, 'No': False})\n",
    "\n",
    "    # Casting all floats in self_score columns to integers\n",
    "\n",
    "    columns_to_convert = ['tech_self_score.C#',\n",
    "                        'tech_self_score.Java',\n",
    "                        'tech_self_score.R',\n",
    "                        'tech_self_score.JavaScript',\n",
    "                        'tech_self_score.Python',\n",
    "                        'tech_self_score.C++',\n",
    "                        'tech_self_score.Ruby',\n",
    "                        'tech_self_score.SPSS',\n",
    "                        'tech_self_score.PHP']\n",
    "\n",
    "    float_to_int_dict = {\n",
    "        1.0: 1,\n",
    "        2.0: 2,\n",
    "        3.0: 3,\n",
    "        4.0: 4,\n",
    "        5.0: 5,\n",
    "        6.0: 6,\n",
    "        7.0: 7,\n",
    "        8.0: 8,\n",
    "        9.0: 9,\n",
    "        10.0: 10,\n",
    "        11.0: 11,\n",
    "        12.0: 12\n",
    "    }\n",
    "\n",
    "    # Use the map() method with the float_to_int_dict to convert floats to integers\n",
    "    for col in columns_to_convert:\n",
    "        df[col] = df[col].map(float_to_int_dict).astype('Int64')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Talent TXTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sparta Day Date</th>\n",
       "      <th>Academy</th>\n",
       "      <th>Name</th>\n",
       "      <th>Psychometrics Score</th>\n",
       "      <th>Presentation Score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>HILARY WILLMORE</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>HILARY WILLMORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>ORLY LORENS</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>ORLY LORENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>ALVIE BLEACKLY</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>ALVIE BLEACKLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>DECK ITZCHAKI</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>DECK ITZCHAKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>WILT PENRITT</td>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "      <td>WILT PENRITT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>London</td>\n",
       "      <td>GODIVA ANDREW</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>GODIVA ANDREW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>London</td>\n",
       "      <td>DORALIA GAPPER</td>\n",
       "      <td>55</td>\n",
       "      <td>22</td>\n",
       "      <td>DORALIA GAPPER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>London</td>\n",
       "      <td>DOE EISOLD</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>DOE EISOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>London</td>\n",
       "      <td>JUDY FINDERS</td>\n",
       "      <td>56</td>\n",
       "      <td>22</td>\n",
       "      <td>JUDY FINDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>London</td>\n",
       "      <td>LORINDA O'CROTTY</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>LORINDA O'CROTTY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4131 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sparta Day Date     Academy              Name  Psychometrics Score   \n",
       "0         2019-08-01  Birmingham   HILARY WILLMORE                   51  \\\n",
       "1         2019-08-01  Birmingham       ORLY LORENS                   51   \n",
       "2         2019-08-01  Birmingham    ALVIE BLEACKLY                   55   \n",
       "3         2019-08-01  Birmingham     DECK ITZCHAKI                   59   \n",
       "4         2019-08-01  Birmingham      WILT PENRITT                   66   \n",
       "...              ...         ...               ...                  ...   \n",
       "4129      2019-10-09      London     GODIVA ANDREW                   46   \n",
       "4130      2019-10-09      London    DORALIA GAPPER                   55   \n",
       "4131      2019-10-09      London        DOE EISOLD                   57   \n",
       "4132      2019-10-09      London      JUDY FINDERS                   56   \n",
       "4133      2019-10-09      London  LORINDA O'CROTTY                   42   \n",
       "\n",
       "      Presentation Score              name  \n",
       "0                     19   HILARY WILLMORE  \n",
       "1                     19       ORLY LORENS  \n",
       "2                     16    ALVIE BLEACKLY  \n",
       "3                     21     DECK ITZCHAKI  \n",
       "4                     25      WILT PENRITT  \n",
       "...                  ...               ...  \n",
       "4129                  19     GODIVA ANDREW  \n",
       "4130                  22    DORALIA GAPPER  \n",
       "4131                  20        DOE EISOLD  \n",
       "4132                  22      JUDY FINDERS  \n",
       "4133                  20  LORINDA O'CROTTY  \n",
       "\n",
       "[4131 rows x 6 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_txts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sparta Day Date</th>\n",
       "      <th>Academy</th>\n",
       "      <th>Name</th>\n",
       "      <th>Psychometrics Score</th>\n",
       "      <th>Presentation Score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sparta Day Date, Academy, Name, Psychometrics Score, Presentation Score, name]\n",
       "Index: []"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicated names\n",
    "talent_txts_df[talent_txts_df['Name'].duplicated()]\n",
    "\n",
    "# we will now compare the sets of duplicated names below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sparta Day Date</th>\n",
       "      <th>Academy</th>\n",
       "      <th>Name</th>\n",
       "      <th>Psychometrics Score</th>\n",
       "      <th>Presentation Score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>London</td>\n",
       "      <td>BETTE</td>\n",
       "      <td>43</td>\n",
       "      <td>27</td>\n",
       "      <td>BETTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sparta Day Date Academy   Name  Psychometrics Score  Presentation Score   \n",
       "353      2019-09-11  London  BETTE                   43                  27  \\\n",
       "\n",
       "      name  \n",
       "353  BETTE  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_txts_df[talent_txts_df['Name'] == 'BETTE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sparta Day Date</th>\n",
       "      <th>Academy</th>\n",
       "      <th>Name</th>\n",
       "      <th>Psychometrics Score</th>\n",
       "      <th>Presentation Score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>London</td>\n",
       "      <td>SHURLOCKE CRINGLE</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>SHURLOCKE CRINGLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sparta Day Date Academy               Name  Psychometrics Score   \n",
       "1930      2019-05-21  London  SHURLOCKE CRINGLE                   52  \\\n",
       "\n",
       "      Presentation Score               name  \n",
       "1930                  21  SHURLOCKE CRINGLE  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_txts_df[talent_txts_df['Name'] == 'SHURLOCKE CRINGLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sparta Day Date</th>\n",
       "      <th>Academy</th>\n",
       "      <th>Name</th>\n",
       "      <th>Psychometrics Score</th>\n",
       "      <th>Presentation Score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>London</td>\n",
       "      <td>NICOLETTE BONEHILL</td>\n",
       "      <td>47</td>\n",
       "      <td>20</td>\n",
       "      <td>NICOLETTE BONEHILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sparta Day Date Academy                Name  Psychometrics Score   \n",
       "1527      2019-11-19  London  NICOLETTE BONEHILL                   47  \\\n",
       "\n",
       "      Presentation Score                name  \n",
       "1527                  20  NICOLETTE BONEHILL  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talent_txts_df[talent_txts_df['Name'] == 'NICOLETTE BONEHILL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[1500, 3239, 3472] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[281], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# The three sets of people seems to be duplicates, due to the proximity of the scores and their names\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39m# Dropping duplicate rows to leave the latest Sparta Day for each person in the dataset\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m talent_txts_df\u001b[39m.\u001b[39;49mdrop(index\u001b[39m=\u001b[39;49m[\u001b[39m1500\u001b[39;49m, \u001b[39m3239\u001b[39;49m, \u001b[39m3472\u001b[39;49m], inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5268\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   5121\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5122\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5129\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5130\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5131\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5132\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5133\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5266\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5267\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5268\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5269\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5270\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5271\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5272\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5273\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5274\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5275\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5276\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6696\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6694\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6695\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6696\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6697\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6698\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[1500, 3239, 3472] not found in axis'"
     ]
    }
   ],
   "source": [
    "# The three sets of people seems to be duplicates, due to the proximity of the scores and their names\n",
    "\n",
    "# Dropping duplicate rows to leave the latest Sparta Day for each person in the dataset\n",
    "talent_txts_df.drop(index=[1500, 3239, 3472], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values in column\n",
    "talent_txts_df['Sparta Day Date'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sparta Day Date</th>\n",
       "      <th>Academy</th>\n",
       "      <th>Name</th>\n",
       "      <th>Psychometrics Score</th>\n",
       "      <th>Presentation Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>HILARY WILLMORE</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>ORLY LORENS</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>ALVIE BLEACKLY</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>DECK ITZCHAKI</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>WILT PENRITT</td>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>London</td>\n",
       "      <td>GODIVA ANDREW</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>London</td>\n",
       "      <td>DORALIA GAPPER</td>\n",
       "      <td>55</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>London</td>\n",
       "      <td>DOE EISOLD</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>London</td>\n",
       "      <td>JUDY FINDERS</td>\n",
       "      <td>56</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>London</td>\n",
       "      <td>LORINDA O'CROTTY</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4131 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sparta Day Date     Academy              Name Psychometrics Score   \n",
       "0         2019-08-01  Birmingham   HILARY WILLMORE                  51  \\\n",
       "1         2019-08-01  Birmingham       ORLY LORENS                  51   \n",
       "2         2019-08-01  Birmingham    ALVIE BLEACKLY                  55   \n",
       "3         2019-08-01  Birmingham     DECK ITZCHAKI                  59   \n",
       "4         2019-08-01  Birmingham      WILT PENRITT                  66   \n",
       "...              ...         ...               ...                 ...   \n",
       "4129      2019-10-09      London     GODIVA ANDREW                  46   \n",
       "4130      2019-10-09      London    DORALIA GAPPER                  55   \n",
       "4131      2019-10-09      London        DOE EISOLD                  57   \n",
       "4132      2019-10-09      London      JUDY FINDERS                  56   \n",
       "4133      2019-10-09      London  LORINDA O'CROTTY                  42   \n",
       "\n",
       "     Presentation Score  \n",
       "0                    19  \n",
       "1                    19  \n",
       "2                    16  \n",
       "3                    21  \n",
       "4                    25  \n",
       "...                 ...  \n",
       "4129                 19  \n",
       "4130                 22  \n",
       "4131                 20  \n",
       "4132                 22  \n",
       "4133                 20  \n",
       "\n",
       "[4131 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casting Sparta Day Date to datetime format\n",
    "talent_txts_df['Sparta Day Date'] = pd.to_datetime(talent_txts_df['Sparta Day Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Birmingham', 'London'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Academy column unique values\n",
    "talent_txts_df['Academy'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Name column to upper case for consistency\n",
    "talent_txts_df['Name'] = talent_txts_df['Name'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['19', '16', '21', '25', '18', '28', '20', '26', '13', '22', '17',\n",
       "       '14', '15', '12', '23', '24', '11', '27', '9', '30', '8', '10',\n",
       "       '29'], dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for out of bounds numbers\n",
    "talent_txts_df['Presentation Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 16, 21, 25, 18, 28, 20, 26, 13, 22, 17, 14, 15, 12, 23, 24, 11,\n",
       "       27,  9, 30,  8, 10, 29])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casting Presentation Score to integers\n",
    "talent_txts_df['Presentation Score'] = talent_txts_df['Presentation Score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['51', '55', '59', '66', '61', '52', '63', '49', '60', '56', '62',\n",
       "       '64', '58', '45', '54', '53', '40', '57', '44', '48', '43', '42',\n",
       "       '69', '67', '50', '46', '65', '47', '39', '72', '41', '71', '37',\n",
       "       '68', '38', '35', '70', '36', '73', '75', '34', '32', '33', '79',\n",
       "       '74'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for out of bounds numbers\n",
    "talent_txts_df['Psychometrics Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting Presentation Score to integers\n",
    "talent_txts_df['Psychometrics Score'] = talent_txts_df['Psychometrics Score'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Clean Talent TXTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_talent_txts_df(df):\n",
    "    # Dropping duplicate rows to leave the latest Sparta Day for each person in the dataset\n",
    "    df.drop(index=[1500, 3239, 3472], inplace=True)\n",
    "\n",
    "    # Casting Sparta Day Date to datetime format\n",
    "    df['Sparta Day Date'] = pd.to_datetime(df['Sparta Day Date'])\n",
    "\n",
    "    # Converting Name column to upper case for consistency\n",
    "    df['Name'] = df['Name'].str.strip().str.upper()\n",
    "\n",
    "    # Casting Presentation Score to integers\n",
    "    df['Presentation Score'] = df['Presentation Score'].astype(int)\n",
    "\n",
    "    # Casting Presentation Score to integers\n",
    "    df['Psychometrics Score'] = df['Psychometrics Score'].astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
